{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "YqkFgymNioLr",
        "UiCXcol6ZaCu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLQjXIIHYCZI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar3pJOOdDTOw"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "Om4li6gXCsc-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foZFb625xP56"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrMfqhld0gcN",
        "outputId": "b5b92fd2-416d-4642-d6bd-1c4748e991bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: backtesting in /usr/local/lib/python3.12/dist-packages (0.6.5)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from backtesting) (2.0.2)\n",
            "Requirement already satisfied: pandas!=0.25.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from backtesting) (2.2.2)\n",
            "Requirement already satisfied: bokeh!=3.0.*,!=3.2.*,>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from backtesting) (3.7.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.12/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=3.0.0->backtesting) (3.1.6)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.12/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=3.0.0->backtesting) (1.3.3)\n",
            "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.12/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=3.0.0->backtesting) (2.6.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.12/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=3.0.0->backtesting) (25.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=3.0.0->backtesting) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.12/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=3.0.0->backtesting) (6.0.3)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=3.0.0->backtesting) (6.4.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.12/dist-packages (from bokeh!=3.0.*,!=3.2.*,>=3.0.0->backtesting) (2025.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas!=0.25.0,>=0.25.0->backtesting) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas!=0.25.0,>=0.25.0->backtesting) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas!=0.25.0,>=0.25.0->backtesting) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=2.9->bokeh!=3.0.*,!=3.2.*,>=3.0.0->backtesting) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas!=0.25.0,>=0.25.0->backtesting) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install backtesting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpQJb6oDs2qY",
        "outputId": "603eae00-1f2b-4c26-9473-502327c41b6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mplfinance in /usr/local/lib/python3.12/dist-packages (0.12.10b0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mplfinance) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from mplfinance) (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mplfinance) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mplfinance) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mplfinance) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mplfinance) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mplfinance) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mplfinance) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mplfinance) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mplfinance) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mplfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->mplfinance) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->mplfinance) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mplfinance) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install mplfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4ETqgzNZnEI",
        "outputId": "60ef38cb-35b3-4972-af6e-0c19f2a5341b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "--2025-10-07 03:23:41--  http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
            "Resolving prdownloads.sourceforge.net (prdownloads.sourceforge.net)... 104.18.12.149, 104.18.13.149, 2606:4700::6812:c95, ...\n",
            "Connecting to prdownloads.sourceforge.net (prdownloads.sourceforge.net)|104.18.12.149|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.sourceforge.net/project/ta-lib/ta-lib/0.4.0/ta-lib-0.4.0-src.tar.gz [following]\n",
            "--2025-10-07 03:23:42--  http://downloads.sourceforge.net/project/ta-lib/ta-lib/0.4.0/ta-lib-0.4.0-src.tar.gz\n",
            "Resolving downloads.sourceforge.net (downloads.sourceforge.net)... 104.18.12.149, 104.18.13.149, 2606:4700::6812:c95, ...\n",
            "Reusing existing connection to prdownloads.sourceforge.net:80.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://netactuate.dl.sourceforge.net/project/ta-lib/ta-lib/0.4.0/ta-lib-0.4.0-src.tar.gz?viasf=1 [following]\n",
            "--2025-10-07 03:23:42--  http://netactuate.dl.sourceforge.net/project/ta-lib/ta-lib/0.4.0/ta-lib-0.4.0-src.tar.gz?viasf=1\n",
            "Resolving netactuate.dl.sourceforge.net (netactuate.dl.sourceforge.net)... 104.225.3.66\n",
            "Connecting to netactuate.dl.sourceforge.net (netactuate.dl.sourceforge.net)|104.225.3.66|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1330299 (1.3M) [application/x-gzip]\n",
            "Saving to: ‘ta-lib-0.4.0-src.tar.gz.1’\n",
            "\n",
            "ta-lib-0.4.0-src.ta 100%[===================>]   1.27M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-10-07 03:23:42 (10.1 MB/s) - ‘ta-lib-0.4.0-src.tar.gz.1’ saved [1330299/1330299]\n",
            "\n",
            "ta-lib/\n",
            "ta-lib/config.sub\n",
            "ta-lib/aclocal.m4\n",
            "ta-lib/CHANGELOG.TXT\n",
            "ta-lib/include/\n",
            "ta-lib/include/ta_abstract.h\n",
            "ta-lib/include/ta_func.h\n",
            "ta-lib/include/ta_common.h\n",
            "ta-lib/include/ta_config.h.in\n",
            "ta-lib/include/Makefile.am\n",
            "ta-lib/include/ta_libc.h\n",
            "ta-lib/include/ta_defs.h\n",
            "ta-lib/missing\n",
            "ta-lib/ta-lib.spec.in\n",
            "ta-lib/config.guess\n",
            "ta-lib/Makefile.in\n",
            "ta-lib/ta-lib.dpkg.in\n",
            "ta-lib/Makefile.am\n",
            "ta-lib/autogen.sh\n",
            "ta-lib/install-sh\n",
            "ta-lib/configure\n",
            "ta-lib/depcomp\n",
            "ta-lib/HISTORY.TXT\n",
            "ta-lib/configure.in\n",
            "ta-lib/autom4te.cache/\n",
            "ta-lib/autom4te.cache/output.0\n",
            "ta-lib/autom4te.cache/requests\n",
            "ta-lib/autom4te.cache/output.1\n",
            "ta-lib/autom4te.cache/traces.0\n",
            "ta-lib/autom4te.cache/traces.1\n",
            "ta-lib/ltmain.sh\n",
            "ta-lib/ta-lib-config.in\n",
            "ta-lib/src/\n",
            "ta-lib/src/ta_func/\n",
            "ta-lib/src/ta_func/ta_MACDFIX.c\n",
            "ta-lib/src/ta_func/ta_CDLPIERCING.c\n",
            "ta-lib/src/ta_func/ta_DIV.c\n",
            "ta-lib/src/ta_func/ta_ROCR100.c\n",
            "ta-lib/src/ta_func/ta_ADXR.c\n",
            "ta-lib/src/ta_func/ta_MAVP.c\n",
            "ta-lib/src/ta_func/ta_CDLCLOSINGMARUBOZU.c\n",
            "ta-lib/src/ta_func/ta_COSH.c\n",
            "ta-lib/src/ta_func/ta_EXP.c\n",
            "ta-lib/src/ta_func/ta_MINMAXINDEX.c\n",
            "ta-lib/src/ta_func/ta_SQRT.c\n",
            "ta-lib/src/ta_func/ta_FLOOR.c\n",
            "ta-lib/src/ta_func/ta_CDLCONCEALBABYSWALL.c\n",
            "ta-lib/src/ta_func/ta_NATR.c\n",
            "ta-lib/src/ta_func/ta_CDLHARAMICROSS.c\n",
            "ta-lib/src/ta_func/ta_MINUS_DM.c\n",
            "ta-lib/src/ta_func/ta_LOG10.c\n",
            "ta-lib/src/ta_func/ta_LINEARREG_ANGLE.c\n",
            "ta-lib/src/ta_func/ta_RSI.c\n",
            "ta-lib/src/ta_func/ta_CDLABANDONEDBABY.c\n",
            "ta-lib/src/ta_func/ta_SAR.c\n",
            "ta-lib/src/ta_func/ta_CDLBREAKAWAY.c\n",
            "ta-lib/src/ta_func/ta_CDLDRAGONFLYDOJI.c\n",
            "ta-lib/src/ta_func/ta_CDLHIGHWAVE.c\n",
            "ta-lib/src/ta_func/ta_CDLKICKING.c\n",
            "ta-lib/src/ta_func/ta_CDLDOJISTAR.c\n",
            "ta-lib/src/ta_func/ta_VAR.c\n",
            "ta-lib/src/ta_func/ta_CDLMATCHINGLOW.c\n",
            "ta-lib/src/ta_func/ta_CDLGAPSIDESIDEWHITE.c\n",
            "ta-lib/src/ta_func/ta_CDLMARUBOZU.c\n",
            "ta-lib/src/ta_func/ta_AROONOSC.c\n",
            "ta-lib/src/ta_func/ta_WCLPRICE.c\n",
            "ta-lib/src/ta_func/ta_CDLEVENINGDOJISTAR.c\n",
            "ta-lib/src/ta_func/ta_CDL3INSIDE.c\n",
            "ta-lib/src/ta_func/ta_OBV.c\n",
            "ta-lib/src/ta_func/ta_AROON.c\n",
            "ta-lib/src/ta_func/ta_CDLBELTHOLD.c\n",
            "ta-lib/src/ta_func/ta_CDLSPINNINGTOP.c\n",
            "ta-lib/src/ta_func/ta_AD.c\n",
            "ta-lib/src/ta_func/ta_MAX.c\n",
            "ta-lib/src/ta_func/ta_CDLENGULFING.c\n",
            "ta-lib/src/ta_func/ta_MINMAX.c\n",
            "ta-lib/src/ta_func/ta_CDLINNECK.c\n",
            "ta-lib/src/ta_func/ta_STDDEV.c\n",
            "ta-lib/src/ta_func/ta_NVI.c\n",
            "ta-lib/src/ta_func/ta_CDLHAMMER.c\n",
            "ta-lib/src/ta_func/ta_ASIN.c\n",
            "ta-lib/src/ta_func/ta_SUM.c\n",
            "ta-lib/src/ta_func/ta_STOCH.c\n",
            "ta-lib/src/ta_func/ta_CDLLONGLEGGEDDOJI.c\n",
            "ta-lib/src/ta_func/ta_MEDPRICE.c\n",
            "ta-lib/src/ta_func/ta_CDL3STARSINSOUTH.c\n",
            "ta-lib/src/ta_func/ta_HT_TRENDMODE.c\n",
            "ta-lib/src/ta_func/ta_BBANDS.c\n",
            "ta-lib/src/ta_func/ta_CDLMORNINGSTAR.c\n",
            "ta-lib/src/ta_func/ta_HT_DCPHASE.c\n",
            "ta-lib/src/ta_func/ta_CDLLONGLINE.c\n",
            "ta-lib/src/ta_func/ta_TAN.c\n",
            "ta-lib/src/ta_func/ta_SMA.c\n",
            "ta-lib/src/ta_func/ta_DX.c\n",
            "ta-lib/src/ta_func/ta_MIDPOINT.c\n",
            "ta-lib/src/ta_func/ta_CDL2CROWS.c\n",
            "ta-lib/src/ta_func/ta_CORREL.c\n",
            "ta-lib/src/ta_func/ta_CDL3BLACKCROWS.c\n",
            "ta-lib/src/ta_func/ta_ADD.c\n",
            "ta-lib/src/ta_func/Makefile.in\n",
            "ta-lib/src/ta_func/ta_CDLTHRUSTING.c\n",
            "ta-lib/src/ta_func/ta_SUB.c\n",
            "ta-lib/src/ta_func/ta_CDLSTALLEDPATTERN.c\n",
            "ta-lib/src/ta_func/ta_CDLTRISTAR.c\n",
            "ta-lib/src/ta_func/ta_MA.c\n",
            "ta-lib/src/ta_func/ta_HT_SINE.c\n",
            "ta-lib/src/ta_func/ta_ACOS.c\n",
            "ta-lib/src/ta_func/ta_CDLSTICKSANDWICH.c\n",
            "ta-lib/src/ta_func/ta_SINH.c\n",
            "ta-lib/src/ta_func/ta_utility.h\n",
            "ta-lib/src/ta_func/ta_CDLSHORTLINE.c\n",
            "ta-lib/src/ta_func/ta_ATAN.c\n",
            "ta-lib/src/ta_func/ta_CDLADVANCEBLOCK.c\n",
            "ta-lib/src/ta_func/ta_CDLKICKINGBYLENGTH.c\n",
            "ta-lib/src/ta_func/ta_CDLSHOOTINGSTAR.c\n",
            "ta-lib/src/ta_func/ta_ROCR.c\n",
            "ta-lib/src/ta_func/ta_WMA.c\n",
            "ta-lib/src/ta_func/ta_CDLDARKCLOUDCOVER.c\n",
            "ta-lib/src/ta_func/ta_CDLXSIDEGAP3METHODS.c\n",
            "ta-lib/src/ta_func/ta_TYPPRICE.c\n",
            "ta-lib/src/ta_func/ta_CDL3WHITESOLDIERS.c\n",
            "ta-lib/src/ta_func/Makefile.am\n",
            "ta-lib/src/ta_func/ta_MACDEXT.c\n",
            "ta-lib/src/ta_func/ta_ADX.c\n",
            "ta-lib/src/ta_func/ta_PLUS_DM.c\n",
            "ta-lib/src/ta_func/ta_CDLUPSIDEGAP2CROWS.c\n",
            "ta-lib/src/ta_func/ta_LN.c\n",
            "ta-lib/src/ta_func/ta_DEMA.c\n",
            "ta-lib/src/ta_func/ta_CDL3OUTSIDE.c\n",
            "ta-lib/src/ta_func/ta_CDLTASUKIGAP.c\n",
            "ta-lib/src/ta_func/ta_MAMA.c\n",
            "ta-lib/src/ta_func/ta_CDLMORNINGDOJISTAR.c\n",
            "ta-lib/src/ta_func/ta_PLUS_DI.c\n",
            "ta-lib/src/ta_func/ta_MININDEX.c\n",
            "ta-lib/src/ta_func/ta_COS.c\n",
            "ta-lib/src/ta_func/ta_HT_TRENDLINE.c\n",
            "ta-lib/src/ta_func/ta_MIDPRICE.c\n",
            "ta-lib/src/ta_func/ta_CEIL.c\n",
            "ta-lib/src/ta_func/ta_TRIMA.c\n",
            "ta-lib/src/ta_func/ta_CDLSEPARATINGLINES.c\n",
            "ta-lib/src/ta_func/ta_ROCP.c\n",
            "ta-lib/src/ta_func/ta_CDLHOMINGPIGEON.c\n",
            "ta-lib/src/ta_func/ta_CDLHANGINGMAN.c\n",
            "ta-lib/src/ta_func/ta_AVGPRICE.c\n",
            "ta-lib/src/ta_func/ta_APO.c\n",
            "ta-lib/src/ta_func/ta_CDLRISEFALL3METHODS.c\n",
            "ta-lib/src/ta_func/ta_TRANGE.c\n",
            "ta-lib/src/ta_func/ta_TSF.c\n",
            "ta-lib/src/ta_func/ta_LINEARREG.c\n",
            "ta-lib/src/ta_func/ta_PVI.c\n",
            "ta-lib/src/ta_func/ta_CDLHIKKAKEMOD.c\n",
            "ta-lib/src/ta_func/ta_MFI.c\n",
            "ta-lib/src/ta_func/ta_CDLHARAMI.c\n",
            "ta-lib/src/ta_func/ta_MACD.c\n",
            "ta-lib/src/ta_func/ta_BETA.c\n",
            "ta-lib/src/ta_func/ta_CDLINVERTEDHAMMER.c\n",
            "ta-lib/src/ta_func/ta_LINEARREG_SLOPE.c\n",
            "ta-lib/src/ta_func/ta_STOCHF.c\n",
            "ta-lib/src/ta_func/ta_MIN.c\n",
            "ta-lib/src/ta_func/ta_CDLIDENTICAL3CROWS.c\n",
            "ta-lib/src/ta_func/ta_CDLRICKSHAWMAN.c\n",
            "ta-lib/src/ta_func/ta_T3.c\n",
            "ta-lib/src/ta_func/ta_CDLMATHOLD.c\n",
            "ta-lib/src/ta_func/ta_CDLUNIQUE3RIVER.c\n",
            "ta-lib/src/ta_func/ta_ADOSC.c\n",
            "ta-lib/src/ta_func/ta_MAXINDEX.c\n",
            "ta-lib/src/ta_func/ta_ULTOSC.c\n",
            "ta-lib/src/ta_func/ta_TRIX.c\n",
            "ta-lib/src/ta_func/ta_MOM.c\n",
            "ta-lib/src/ta_func/ta_CDLDOJI.c\n",
            "ta-lib/src/ta_func/ta_EMA.c\n",
            "ta-lib/src/ta_func/ta_STOCHRSI.c\n",
            "ta-lib/src/ta_func/ta_ROC.c\n",
            "ta-lib/src/ta_func/ta_CDLEVENINGSTAR.c\n",
            "ta-lib/src/ta_func/ta_CDLCOUNTERATTACK.c\n",
            "ta-lib/src/ta_func/ta_LINEARREG_INTERCEPT.c\n",
            "ta-lib/src/ta_func/ta_SAREXT.c\n",
            "ta-lib/src/ta_func/ta_WILLR.c\n",
            "ta-lib/src/ta_func/ta_MULT.c\n",
            "ta-lib/src/ta_func/ta_ATR.c\n",
            "ta-lib/src/ta_func/ta_BOP.c\n",
            "ta-lib/src/ta_func/ta_CMO.c\n",
            "ta-lib/src/ta_func/ta_CDLONNECK.c\n",
            "ta-lib/src/ta_func/ta_CCI.c\n",
            "ta-lib/src/ta_func/ta_CDLLADDERBOTTOM.c\n",
            "ta-lib/src/ta_func/ta_HT_PHASOR.c\n",
            "ta-lib/src/ta_func/ta_utility.c\n",
            "ta-lib/src/ta_func/ta_PPO.c\n",
            "ta-lib/src/ta_func/ta_CDLHIKKAKE.c\n",
            "ta-lib/src/ta_func/ta_HT_DCPERIOD.c\n",
            "ta-lib/src/ta_func/ta_CDL3LINESTRIKE.c\n",
            "ta-lib/src/ta_func/ta_TEMA.c\n",
            "ta-lib/src/ta_func/ta_SIN.c\n",
            "ta-lib/src/ta_func/ta_MINUS_DI.c\n",
            "ta-lib/src/ta_func/ta_KAMA.c\n",
            "ta-lib/src/ta_func/ta_TANH.c\n",
            "ta-lib/src/ta_func/ta_CDLTAKURI.c\n",
            "ta-lib/src/ta_func/ta_CDLGRAVESTONEDOJI.c\n",
            "ta-lib/src/ta_common/\n",
            "ta-lib/src/ta_common/ta_pragma.h\n",
            "ta-lib/src/ta_common/ta_magic_nb.h\n",
            "ta-lib/src/ta_common/ta_retcode.csv\n",
            "ta-lib/src/ta_common/Makefile.in\n",
            "ta-lib/src/ta_common/Makefile.am\n",
            "ta-lib/src/ta_common/ta_memory.h\n",
            "ta-lib/src/ta_common/ta_version.c\n",
            "ta-lib/src/ta_common/ta_global.h\n",
            "ta-lib/src/ta_common/ta_global.c\n",
            "ta-lib/src/ta_common/ta_retcode.c\n",
            "ta-lib/src/Makefile.in\n",
            "ta-lib/src/ta_abstract/\n",
            "ta-lib/src/ta_abstract/frames/\n",
            "ta-lib/src/ta_abstract/frames/ta_frame.c\n",
            "ta-lib/src/ta_abstract/frames/ta_frame.h\n",
            "ta-lib/src/ta_abstract/excel_glue.c\n",
            "ta-lib/src/ta_abstract/ta_frame_priv.h\n",
            "ta-lib/src/ta_abstract/ta_func_api.c\n",
            "ta-lib/src/ta_abstract/Makefile.in\n",
            "ta-lib/src/ta_abstract/ta_def_ui.h\n",
            "ta-lib/src/ta_abstract/Makefile.am\n",
            "ta-lib/src/ta_abstract/ta_abstract.c\n",
            "ta-lib/src/ta_abstract/ta_group_idx.c\n",
            "ta-lib/src/ta_abstract/tables/\n",
            "ta-lib/src/ta_abstract/tables/table_u.c\n",
            "ta-lib/src/ta_abstract/tables/table_x.c\n",
            "ta-lib/src/ta_abstract/tables/table_r.c\n",
            "ta-lib/src/ta_abstract/tables/table_f.c\n",
            "ta-lib/src/ta_abstract/tables/table_j.c\n",
            "ta-lib/src/ta_abstract/tables/table_e.c\n",
            "ta-lib/src/ta_abstract/tables/table_t.c\n",
            "ta-lib/src/ta_abstract/tables/table_n.c\n",
            "ta-lib/src/ta_abstract/tables/table_i.c\n",
            "ta-lib/src/ta_abstract/tables/table_c.c\n",
            "ta-lib/src/ta_abstract/tables/table_l.c\n",
            "ta-lib/src/ta_abstract/tables/table_k.c\n",
            "ta-lib/src/ta_abstract/tables/table_g.c\n",
            "ta-lib/src/ta_abstract/tables/table_d.c\n",
            "ta-lib/src/ta_abstract/tables/table_h.c\n",
            "ta-lib/src/ta_abstract/tables/table_o.c\n",
            "ta-lib/src/ta_abstract/tables/table_b.c\n",
            "ta-lib/src/ta_abstract/tables/table_q.c\n",
            "ta-lib/src/ta_abstract/tables/table_v.c\n",
            "ta-lib/src/ta_abstract/tables/table_m.c\n",
            "ta-lib/src/ta_abstract/tables/table_s.c\n",
            "ta-lib/src/ta_abstract/tables/table_y.c\n",
            "ta-lib/src/ta_abstract/tables/table_p.c\n",
            "ta-lib/src/ta_abstract/tables/table_z.c\n",
            "ta-lib/src/ta_abstract/tables/table_a.c\n",
            "ta-lib/src/ta_abstract/tables/table_w.c\n",
            "ta-lib/src/ta_abstract/ta_def_ui.c\n",
            "ta-lib/src/ta_abstract/templates/\n",
            "ta-lib/src/ta_abstract/templates/ta_x.c.template\n",
            "ta-lib/src/ta_abstract/templates/ta_java_defs.h.template\n",
            "ta-lib/src/ta_abstract/templates/excel_glue.c.template\n",
            "ta-lib/src/ta_abstract/templates/ta_group_idx.c.template\n",
            "ta-lib/src/ta_abstract/templates/ta_frame.c.template\n",
            "ta-lib/src/ta_abstract/templates/CoreAnnotated.java.template\n",
            "ta-lib/src/ta_abstract/templates/ta_func.h.template\n",
            "ta-lib/src/ta_abstract/templates/ta_frame.h.template\n",
            "ta-lib/src/ta_abstract/templates/Makefile.am.template\n",
            "ta-lib/src/ta_abstract/templates/ta_func_api.c.template\n",
            "ta-lib/src/ta_abstract/templates/ta_func.swg.template\n",
            "ta-lib/src/ta_abstract/templates/ta_retcode.c.template\n",
            "ta-lib/src/ta_abstract/ta_java_defs.h\n",
            "ta-lib/src/Makefile.am\n",
            "ta-lib/src/tools/\n",
            "ta-lib/src/tools/ta_regtest/\n",
            "ta-lib/src/tools/ta_regtest/test_util.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func.h\n",
            "ta-lib/src/tools/ta_regtest/test_data.c\n",
            "ta-lib/src/tools/ta_regtest/ta_gDataHigh.c\n",
            "ta-lib/src/tools/ta_regtest/Makefile.in\n",
            "ta-lib/src/tools/ta_regtest/test_internals.c\n",
            "ta-lib/src/tools/ta_regtest/Makefile.am\n",
            "ta-lib/src/tools/ta_regtest/ta_regtest.c\n",
            "ta-lib/src/tools/ta_regtest/ta_gDataOpen.c\n",
            "ta-lib/src/tools/ta_regtest/ta_gDataClose.c\n",
            "ta-lib/src/tools/ta_regtest/test_abstract.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_bbands.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_stddev.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_1in_2out.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_sar.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_1in_1out.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_trange.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_macd.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_po.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_per_hlc.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_mom.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_per_ohlc.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_adx.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_candlestick.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_rsi.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_per_ema.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_minmax.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_per_hlcv.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_per_hl.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_stoch.c\n",
            "ta-lib/src/tools/ta_regtest/ta_test_func/test_ma.c\n",
            "ta-lib/src/tools/ta_regtest/ta_error_number.h\n",
            "ta-lib/src/tools/ta_regtest/ta_test_priv.h\n",
            "ta-lib/src/tools/ta_regtest/ReadMe.txt\n",
            "ta-lib/src/tools/ta_regtest/ta_gDataLow.c\n",
            "ta-lib/src/tools/Makefile.in\n",
            "ta-lib/src/tools/Makefile.am\n",
            "ta-lib/src/tools/gen_code/\n",
            "ta-lib/src/tools/gen_code/java/\n",
            "ta-lib/src/tools/gen_code/java/PrettyCode.java\n",
            "ta-lib/src/tools/gen_code/java/Main.java\n",
            "ta-lib/src/tools/gen_code/gen_code.c\n",
            "ta-lib/src/tools/gen_code/Makefile.in\n",
            "ta-lib/src/tools/gen_code/Makefile.am\n",
            "ta-lib/src/tools/gen_code/mcpp.exe\n",
            "[Errno 2] No such file or directory: 'ta-lib-0.4.0/'\n",
            "/\n",
            "/bin/bash: line 1: ./configure: No such file or directory\n",
            "make: *** No targets specified and no makefile found.  Stop.\n",
            "make: *** No rule to make target 'install'.  Stop.\n",
            "/\n",
            "Requirement already satisfied: Ta-Lib in /usr/local/lib/python3.12/dist-packages (0.6.7)\n",
            "Requirement already satisfied: build in /usr/local/lib/python3.12/dist-packages (from Ta-Lib) (1.3.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (from Ta-Lib) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from Ta-Lib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build->Ta-Lib) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build->Ta-Lib) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "# Ставим зависимости\n",
        "!apt-get install -y build-essential\n",
        "!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
        "!tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
        "%cd ta-lib-0.4.0/\n",
        "!./configure --prefix=/usr\n",
        "!make\n",
        "!make install\n",
        "%cd ..\n",
        "# Устанавливаем python-обертку\n",
        "!pip install Ta-Lib\n",
        "import talib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "T1V6fkITwA5b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import mplfinance as mpf\n",
        "import talib\n",
        "import random\n",
        "import datetime\n",
        "import time\n",
        "from tabulate import tabulate\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elbbJtO4xUZt"
      },
      "source": [
        "## Funcrions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIEJvGR_aBDl"
      },
      "source": [
        "### Get Binance klines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "_cWN2e0KJjQZ"
      },
      "outputs": [],
      "source": [
        "from datetime import timezone, datetime\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import csv\n",
        "import io\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "def generate_months(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, '%Y-%m')\n",
        "    end_date = datetime.strptime(end_date, '%Y-%m')\n",
        "    months = []\n",
        "\n",
        "    while start_date <= end_date:\n",
        "        months.append(start_date.strftime('%Y-%m'))\n",
        "        start_date = start_date + relativedelta(months=1)\n",
        "\n",
        "    return months\n",
        "\n",
        "\n",
        "# Загрузка данных с Binance\n",
        "def download_klines(symbol, interval, start_date, end_date):\n",
        "    months = generate_months(start_date, end_date)\n",
        "    if not os.path.exists('klines'):\n",
        "        os.mkdir('klines')\n",
        "\n",
        "    klines = {\n",
        "        'Date': [], 'Open': [], 'High': [], 'Low': [], 'Close': [], 'Volume': []\n",
        "    }\n",
        "\n",
        "    for month in months:\n",
        "        filename = f\"{symbol}-{interval}-{month}.zip\"\n",
        "        file_path = f\"klines/{filename}\"\n",
        "\n",
        "        if not os.path.exists(file_path) or os.path.getsize(file_path) == 0:\n",
        "            url = f\"https://data.binance.vision/data/futures/um/monthly/klines/{symbol}/{interval}/{filename}\"\n",
        "            try:\n",
        "                r = requests.get(url, allow_redirects=True)\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    f.write(r.content)\n",
        "            except Exception as e:\n",
        "                print(f\"Ошибка загрузки файла {filename}: {e}. Пропускаем.\")\n",
        "                continue\n",
        "\n",
        "        try:\n",
        "            with zipfile.ZipFile(file_path, 'r') as zip_file:\n",
        "                with zip_file.open(f\"{symbol}-{interval}-{month}.csv\", 'r') as csv_file:\n",
        "                    csv_reader = csv.reader(io.TextIOWrapper(csv_file, 'utf-8'))\n",
        "                    for row in csv_reader:\n",
        "                        if row[0].isdigit():\n",
        "                            klines['Date'].append(datetime.fromtimestamp(int(row[0]) / 1000, tz=timezone.utc))\n",
        "                            klines['Open'].append(float(row[1]))\n",
        "                            klines['High'].append(float(row[2]))\n",
        "                            klines['Low'].append(float(row[3]))\n",
        "                            klines['Close'].append(float(row[4]))\n",
        "                            klines['Volume'].append(float(row[5]))\n",
        "        except (zipfile.BadZipFile, KeyError):\n",
        "            print(f\"Ошибка: Файл {file_path} поврежден или не является ZIP. Пропускаем.\")\n",
        "            continue\n",
        "\n",
        "\n",
        "    if not klines['Date']:\n",
        "        raise ValueError(f\"Нет доступных данных для {symbol} в диапазоне {start_date} - {end_date}\")\n",
        "\n",
        "    df = pd.DataFrame(klines)\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    df.set_index('Date', inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxlXMQHcaHIA"
      },
      "source": [
        "### Candle patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "ZVKGG3PoPhWy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def detect_candlestick_patterns(\n",
        "    df,\n",
        "    doji_th=0.1,\n",
        "    hammer_lower_mult=2.0,\n",
        "    hammer_upper_mult=0.3,\n",
        "    small_body_factor=0.5,\n",
        "    min_body_pct=0.2\n",
        "):\n",
        "    df = df.copy()\n",
        "    o = df['open'].astype(float)\n",
        "    h = df['high'].astype(float)\n",
        "    l = df['low'].astype(float)\n",
        "    c = df['close'].astype(float)\n",
        "\n",
        "    prev_o = o.shift(1); prev_h = h.shift(1); prev_l = l.shift(1); prev_c = c.shift(1)\n",
        "    pre_prev_o = o.shift(2); pre_prev_c = c.shift(2)\n",
        "\n",
        "    # --- Базовые величины ---\n",
        "    df['body'] = c - o\n",
        "    df['body_abs'] = df['body'].abs()\n",
        "    df['range'] = (h - l).replace(0, np.nan)\n",
        "    df['upper_shadow'] = h - np.maximum(o, c)\n",
        "    df['lower_shadow'] = np.minimum(o, c) - l\n",
        "    df['body_pct_of_range'] = df['body_abs'] / df['range']\n",
        "\n",
        "    # --- Doji ---\n",
        "    df['doji'] = (df['range'].isna() & (df['body_abs'] == 0)) | \\\n",
        "                 (df['body_abs'] <= doji_th * df['range'])\n",
        "\n",
        "    # --- Hammer (бычий сигнал) ---\n",
        "    df['hammer'] = (\n",
        "        (df['lower_shadow'] >= hammer_lower_mult * df['body_abs']) &\n",
        "        (df['upper_shadow'] <= hammer_upper_mult * df['body_abs']) &\n",
        "        (df['body_pct_of_range'] <= 0.5)\n",
        "    )\n",
        "\n",
        "    # --- Inverted Hammer ---\n",
        "    df['inverted_hammer'] = (\n",
        "        (df['upper_shadow'] >= hammer_lower_mult * df['body_abs']) &\n",
        "        (df['lower_shadow'] <= hammer_upper_mult * df['body_abs']) &\n",
        "        (df['body_pct_of_range'] <= 0.5)\n",
        "    )\n",
        "\n",
        "    # --- Bullish Engulfing ---\n",
        "    prev_body_abs = (prev_c - prev_o).abs()\n",
        "    df['bullish_engulfing'] = (\n",
        "        (prev_c < prev_o) & (c > o) & (o < prev_c) & (c > prev_o) &\n",
        "        (df['body_abs'] > prev_body_abs)\n",
        "    ).fillna(False)\n",
        "\n",
        "    # --- Bearish Engulfing ---\n",
        "    df['bearish_engulfing'] = (\n",
        "        (prev_c > prev_o) & (c < o) & (o > prev_c) & (c < prev_o) &\n",
        "        (df['body_abs'] > prev_body_abs)\n",
        "    ).fillna(False)\n",
        "\n",
        "    # --- Piercing Line (бычий) ---\n",
        "    df['piercing_line'] = (\n",
        "        (prev_c < prev_o) & (o < prev_c) & (c > (prev_o + prev_c) / 2)\n",
        "    ).fillna(False)\n",
        "\n",
        "    # --- Dark Cloud Cover (медвежий) ---\n",
        "    df['dark_cloud'] = (\n",
        "        (prev_c > prev_o) & (o > prev_h) & (c < (prev_o + prev_c) / 2) & (c > prev_o)\n",
        "    ).fillna(False)\n",
        "\n",
        "    # --- Morning Star (бычий, 3 свечи) ---\n",
        "    prev_body_abs = (prev_c - prev_o).abs()\n",
        "    pre_prev_body_abs = (pre_prev_c - pre_prev_o).abs()\n",
        "    df['morning_star'] = (\n",
        "        (pre_prev_c < pre_prev_o) &\n",
        "        (prev_body_abs <= small_body_factor * pre_prev_body_abs) &\n",
        "        (c > o) & (c > (pre_prev_o + pre_prev_c) / 2)\n",
        "    ).fillna(False)\n",
        "\n",
        "    # --- Evening Star (медвежий, 3 свечи) ---\n",
        "    df['evening_star'] = (\n",
        "        (pre_prev_c > pre_prev_o) &\n",
        "        (prev_body_abs <= small_body_factor * pre_prev_body_abs) &\n",
        "        (c < o) & (c < (pre_prev_o + pre_prev_c) / 2)\n",
        "    ).fillna(False)\n",
        "\n",
        "    # --- Three White Soldiers ---\n",
        "    o0, o1, o2 = o.shift(2), o.shift(1), o\n",
        "    c0, c1, c2 = c.shift(2), c.shift(1), c\n",
        "    df['three_white_soldiers'] = (\n",
        "        (c0 > o0) & (c1 > o1) & (c2 > o2) &\n",
        "        (c2 > c1) & (c1 > c0) &\n",
        "        (o1 > o0) & (o2 > o1)\n",
        "    ).fillna(False)\n",
        "\n",
        "    # --- Three Black Crows (медвежий аналог) ---\n",
        "    df['three_black_crows'] = (\n",
        "        (c0 < o0) & (c1 < o1) & (c2 < o2) &\n",
        "        (c2 < c1) & (c1 < c0) &\n",
        "        (o1 < o0) & (o2 < o1)\n",
        "    ).fillna(False)\n",
        "\n",
        "    # --- Harami Cross ---\n",
        "    prev_body_top = np.maximum(prev_o, prev_c)\n",
        "    prev_body_bottom = np.minimum(prev_o, prev_c)\n",
        "    harami_cross = (\n",
        "        df['doji'] & (h < prev_body_top) & (l > prev_body_bottom) &\n",
        "        (prev_body_abs >= (min_body_pct * df['range'].shift(1)))\n",
        "    )\n",
        "    df['harami_cross'] = harami_cross.fillna(False)\n",
        "\n",
        "    # --- Bearish Harami ---\n",
        "    df['bearish_harami'] = (\n",
        "        (prev_c > prev_o) & (c < o) &\n",
        "        (h < prev_c) & (l > prev_o)\n",
        "    ).fillna(False)\n",
        "\n",
        "    # Очистка вспомогательных колонок\n",
        "    df = df.drop(columns=[\n",
        "        'body','body_abs','range','upper_shadow','lower_shadow','body_pct_of_range'\n",
        "    ])\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "p7I8YnlQaQKl"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# def detect_candlestick_patterns(df,\n",
        "#                                 doji_th=0.1,               # doji: тело <= 10% от range\n",
        "#                                 hammer_lower_mult=2.0,     # lower_shadow >= 2 * body\n",
        "#                                 hammer_upper_mult=0.3,     # upper_shadow <= 0.3 * body\n",
        "#                                 small_body_factor=0.5,     # middle candle size relative threshold for morning star\n",
        "#                                 min_body_pct=0.2):         # minimum body size relative to candle range for \"strong\" bodies\n",
        "#     # ASSUME df has numeric columns: 'open','high','low','close'\n",
        "#     df = df.copy()\n",
        "\n",
        "#     o = df['open'].astype(float)\n",
        "#     h = df['high'].astype(float)\n",
        "#     l = df['low'].astype(float)\n",
        "#     c = df['close'].astype(float)\n",
        "\n",
        "#     prev_o = o.shift(1)\n",
        "#     prev_h = h.shift(1)\n",
        "#     prev_l = l.shift(1)\n",
        "#     prev_c = c.shift(1)\n",
        "\n",
        "#     pre_prev_o = o.shift(2)\n",
        "#     pre_prev_c = c.shift(2)\n",
        "\n",
        "#     # basic measures\n",
        "#     df['body'] = c - o\n",
        "#     df['body_abs'] = df['body'].abs()\n",
        "#     df['range'] = (h - l).replace(0, np.nan)   # avoid div by zero, keep NaN for zero-range\n",
        "#     df['upper_shadow'] = h - np.maximum(o, c)\n",
        "#     df['lower_shadow'] = np.minimum(o, c) - l\n",
        "#     df['body_pct_of_range'] = df['body_abs'] / df['range']\n",
        "\n",
        "#     # DOJI (relative to candle range)\n",
        "#     df['doji'] = (df['range'].isna() & (df['body_abs'] == 0)) | (df['body_abs'] <= doji_th * df['range'])\n",
        "\n",
        "#     # HAMMER (both bullish or bearish allowed)\n",
        "#     hammer_cond = (\n",
        "#         (df['lower_shadow'] >= hammer_lower_mult * df['body_abs']) &\n",
        "#         (df['upper_shadow'] <= hammer_upper_mult * df['body_abs']) &\n",
        "#         (df['body_pct_of_range'] <= 0.5)   # body not too large relative to range\n",
        "#     )\n",
        "#     df['hammer'] = hammer_cond\n",
        "\n",
        "#     # INVERTED HAMMER\n",
        "#     inv_hammer_cond = (\n",
        "#         (df['upper_shadow'] >= hammer_lower_mult * df['body_abs']) &\n",
        "#         (df['lower_shadow'] <= hammer_upper_mult * df['body_abs']) &\n",
        "#         (df['body_pct_of_range'] <= 0.5)\n",
        "#     )\n",
        "#     df['inverted_hammer'] = inv_hammer_cond\n",
        "\n",
        "#     # BULLISH ENGULFING\n",
        "#     prev_body_abs = (prev_c - prev_o).abs()\n",
        "#     bull_engulf = (\n",
        "#         (prev_c < prev_o) &           # previous bearish\n",
        "#         (c > o) &                     # current bullish\n",
        "#         (o < prev_c) &                # current open below previous close (i.e. below previous body top)\n",
        "#         (c > prev_o) &                # current close above previous open (engulf)\n",
        "#         (df['body_abs'] > prev_body_abs)  # optional: current body bigger than previous\n",
        "#     )\n",
        "#     df['bullish_engulfing'] = bull_engulf.fillna(False)\n",
        "\n",
        "#     # PIERCING LINE (classic definition)\n",
        "#     piercing = (\n",
        "#         (prev_c < prev_o) &  # prev bearish\n",
        "#         (o < prev_l) &       # current open below previous low (gap down) -- can relax to prev_c if desired\n",
        "#         (c > (prev_o + prev_c) / 2)  # close into upper half of previous body\n",
        "#     )\n",
        "#     df['piercing_line'] = piercing.fillna(False)\n",
        "\n",
        "#     # MORNING STAR (3-candle pattern)\n",
        "#     # 1) pre_prev bearish\n",
        "#     # 2) previous small body relative to pre_prev\n",
        "#     # 3) current bullish and closes above midpoint of pre_prev body\n",
        "#     prev_body_abs = (prev_c - prev_o).abs()\n",
        "#     pre_prev_body_abs = (pre_prev_c - pre_prev_o).abs()\n",
        "#     morning_star = (\n",
        "#         (pre_prev_c < pre_prev_o) &\n",
        "#         (prev_body_abs <= small_body_factor * pre_prev_body_abs) &\n",
        "#         (c > o) &\n",
        "#         (o < prev_c) &  # current opens below previous close (gap or inside)\n",
        "#         (c > (pre_prev_o + pre_prev_c) / 2)\n",
        "#     )\n",
        "#     df['morning_star'] = morning_star.fillna(False)\n",
        "\n",
        "#     # THREE WHITE SOLDIERS (vectorized)\n",
        "#     o0 = o.shift(2); o1 = o.shift(1); o2 = o\n",
        "#     c0 = c.shift(2); c1 = c.shift(1); c2 = c\n",
        "#     body0 = (c0 - o0).abs(); body1 = (c1 - o1).abs(); body2 = (c2 - o2).abs()\n",
        "#     three_ws = (\n",
        "#         (c0 > o0) & (c1 > o1) & (c2 > o2) &               # all bullish\n",
        "#         (c2 > c1) & (c1 > c0) &                            # ascending closes\n",
        "#         (o1 > o0) & (o2 > o1) &                            # opens move upward\n",
        "#         (body0 >= min_body_pct * (h.shift(2) - l.shift(2)).replace(0, np.nan)) &\n",
        "#         (body1 >= min_body_pct * (h.shift(1) - l.shift(1)).replace(0, np.nan)) &\n",
        "#         (body2 >= min_body_pct * (h - l).replace(0, np.nan)) &\n",
        "#         (o1 < c0) & (o2 < c1)                              # opens within previous bodies (not strict gap)\n",
        "#     )\n",
        "#     df['three_white_soldiers'] = three_ws.fillna(False)\n",
        "\n",
        "#     # HARAMI CROSS (doji inside previous real body) — generalized both directions\n",
        "#     prev_body_top = np.maximum(prev_o, prev_c)\n",
        "#     prev_body_bottom = np.minimum(prev_o, prev_c)\n",
        "#     harami_cross = (\n",
        "#         df['doji'] &\n",
        "#         (df['high'] < prev_body_top) &\n",
        "#         (df['low'] > prev_body_bottom) &\n",
        "#         (prev_body_abs >= (min_body_pct * df['range'].shift(1)))  # prev body not tiny\n",
        "#     )\n",
        "#     df['harami_cross'] = harami_cross.fillna(False)\n",
        "\n",
        "#     # clean helper columns if you like\n",
        "#     df = df.drop(columns=['body','body_abs','range','upper_shadow','lower_shadow','body_pct_of_range'])\n",
        "#     return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "UIwzacxTa0SL"
      },
      "outputs": [],
      "source": [
        "# # functions for calculating patterns\n",
        "# import pandas as pd\n",
        "\n",
        "# def is_doji(row, threshold=0.1):\n",
        "#     return abs(row['open'] - row['close']) <= threshold\n",
        "\n",
        "# def is_hammer(row):\n",
        "#     body = abs(row['open'] - row['close'])\n",
        "#     lower_shadow = row['open'] - row['low'] if row['open'] <  row['close'] else row['close'] - row['low']\n",
        "#     upper_shadow = row['high'] - row['close'] if row['open'] <  row['close'] else row['high'] - row['open']\n",
        "#     return lower_shadow > 2 * body and upper_shadow < body\n",
        "\n",
        "# def is_bullish_engulfing(current_row, previous_row):\n",
        "#     return previous_row['close'] < previous_row['open'] and current_row['close'] > current_row['open'] and \\\n",
        "#            current_row['open'] < previous_row['close'] and current_row['close'] > previous_row['open']\n",
        "\n",
        "# def is_piercing_line(current_row, previous_row):\n",
        "#     return previous_row['close'] < previous_row['open'] and current_row['close'] > current_row['open'] and \\\n",
        "#             current_row['open'] < previous_row['low'] and current_row['close'] > (previous_row['open'] + previous_row['close']) / 2\n",
        "\n",
        "# def is_morning_star(current_row, previous_row, pre_previous_row):\n",
        "#     return pre_previous_row['close'] < pre_previous_row['open'] and \\\n",
        "#           abs(previous_row['close'] - previous_row['open']) < abs(pre_previous_row['close'] - pre_previous_row['open']) / 2 and \\\n",
        "#           current_row['close'] > current_row['open'] and \\\n",
        "#           current_row['open'] < previous_row['close'] and \\\n",
        "#           current_row['close'] > (previous_row['close'] + previous_row['open']) / 2\n",
        "\n",
        "# def is_inverted_hammer(row):\n",
        "#     body = abs(row['open'] - row['close'])\n",
        "#     upper_shadow = row['high'] - row['close'] if row['open'] <  row['close'] else row['high'] - row['open']\n",
        "#     lower_shadow = row['open'] - row['low'] if row['open'] <  row['close'] else row['close'] - row['low']\n",
        "#     return upper_shadow > 2 * body and lower_shadow < body\n",
        "\n",
        "# def is_three_white_soldiers(df, idx):\n",
        "#     if idx < 2:\n",
        "#         return False\n",
        "#     current = df.iloc[idx]\n",
        "#     prev1 = df.iloc[idx - 1]\n",
        "#     prev2 = df.iloc[idx - 2]\n",
        "#     return all([current['close'] > current['open'], prev1['close'] > prev1['open'], prev2['close'] > prev2['open']]) and \\\n",
        "#            all([current['open'] > prev1['close'], prev1['open'] > prev2['close']]) and \\\n",
        "#            all([current['close'] > prev1['close'], prev1['close'] > prev2['close']])\n",
        "\n",
        "# def is_harami_cross(current_row, previous_row):\n",
        "#     return abs(current_row['open'] - current_row['close']) < (current_row['high'] - current_row['low']) * 0.1 and \\\n",
        "#            previous_row['open'] > previous_row['close'] and current_row['high'] < previous_row['open' ] and current_row['low'] > previous_row['close']\n",
        "\n",
        "# data['doji'] = data.apply(is_doji, axis=1)\n",
        "# data['hammer'] = data.apply(is_hammer, axis=1)\n",
        "# data['bull_engulfing'] = data.apply(lambda row: is_bullish_engulfing(row, data.iloc[data.index.get_loc(row.name) - 1]) if data.index.get_loc(row.name) > 0 else False, axis=1)\n",
        "# data['piercing_line'] = data.apply(lambda row: is_piercing_line(row, data.iloc[data.index.get_loc(row.name) - 1]) if data.index.get_loc(row.name) > 0 else False, axis=1)\n",
        "# data['morning_star'] = data.apply(lambda row: is_morning_star(row, data.iloc[data.index.get_loc(row.name) - 1], data.iloc[data.index.get_loc(row.name) - 2]) if data.index.get_loc(row.name) > 1 else False, axis=1)\n",
        "# data['inverted_hammer'] = data.apply(is_inverted_hammer, axis=1)\n",
        "# data['three_white_soldiers'] = data.apply(lambda row: is_three_white_soldiers(data, data.index.get_loc(row.name)), axis=1)\n",
        "# data['harami_cross'] = data.apply(lambda row: is_harami_cross(row, data.iloc[data.index.get_loc(row.name) - 1]) if data.index.get_loc(row.name) > 0 else False, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "LObR3RcUaLUJ"
      },
      "outputs": [],
      "source": [
        "from ast import pattern\n",
        "# Function for analyzing candlestick patterns\n",
        "\n",
        "def plot_random_pattern(data, pattern_column, pattern_name):\n",
        "    patterns = data[data[pattern_column] != 0]\n",
        "\n",
        "    if patterns.empty:\n",
        "      print(f\"No occurences of {pattern_name} pattern found.\")\n",
        "      return\n",
        "\n",
        "    random_index = random.choice(patterns.index)\n",
        "    start_index = max(0, data.index.get_loc(random_index) - 20)\n",
        "    end_index = min(len(data), data.index.get_loc(random_index) + 20)\n",
        "\n",
        "    data_window = data.iloc[start_index:end_index+1]\n",
        "\n",
        "    fig, axlist = mpf.plot(data_window, type='candle', style='nightclouds', volume=True,\n",
        "                          title=f'{pattern_name} Pattern Detection at {random_index.date()}',\n",
        "                          show_nontrading=True, returnfig=True, figsize=(12,6))\n",
        "\n",
        "    axes = axlist[0]\n",
        "    pattern_row = data.loc[random_index]\n",
        "\n",
        "    # Add a short line to a candlestick plot\n",
        "    axes.annotate('', xy=(random_index, pattern_row['high']),\n",
        "                  xytext=(random_index, pattern_row['high'] + 0.15), # set the line size\n",
        "                  arrowprops=dict(facecolor='magenta', edgecolor='magenta', arrowstyle='->', lw=1.5))\n",
        "\n",
        "    axes.text(random_index, pattern_row['high'] + 0.2, pattern_name,\n",
        "              horizontalalignment='center', verticalalignment='bottom', fontsize=10, color='magenta')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kDfI9FVbwMy"
      },
      "source": [
        "### Stationarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "74OopnzSbz_S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "def adf_test(series, p_threshold=0.05):\n",
        "    \"\"\"Проверка стационарности ряда через ADF-тест\"\"\"\n",
        "    series = series.dropna()\n",
        "    if series.nunique() < 2:  # слишком мало уникальных значений\n",
        "        return False\n",
        "    try:\n",
        "        result = adfuller(series)\n",
        "        p_value = result[1]\n",
        "        t_test = result[0] < result[4][\"5%\"]\n",
        "        return p_value < p_threshold and t_test\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "def make_stationary(data, p_threshold=0.05):\n",
        "    \"\"\"\n",
        "    Проверяет все признаки на стационарность и приводит нестационарные к стационарному виду.\n",
        "    data - DataFrame с фичами\n",
        "    \"\"\"\n",
        "    df = data.copy()\n",
        "    non_stationaries = []\n",
        "\n",
        "    # 1. Проверяем исходные признаки\n",
        "    for col in df.columns:\n",
        "        col_data = df[col].replace([np.inf, -np.inf], np.nan).dropna()\n",
        "        if len(col_data) > 10 and not adf_test(col_data, p_threshold=p_threshold):\n",
        "            non_stationaries.append(col)\n",
        "\n",
        "    print(f\"Нестационарные признаки: {len(non_stationaries)}\")\n",
        "\n",
        "    # 2. Пробуем разные трансформации\n",
        "    for col in non_stationaries:\n",
        "        transformed = None\n",
        "        col_data = df[col].replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "        # Попробуем log (только для положительных)\n",
        "        if (col_data > 0).all():\n",
        "            log_series = np.log(col_data)\n",
        "            if adf_test(log_series, p_threshold):\n",
        "                transformed = log_series\n",
        "            else:\n",
        "                # log + diff\n",
        "                log_diff = np.log(col_data).diff()\n",
        "                if adf_test(log_diff.dropna(), p_threshold):\n",
        "                    transformed = log_diff\n",
        "\n",
        "        # Если log не помог → diff\n",
        "        if transformed is None:\n",
        "            diff_series = col_data.diff()\n",
        "            if adf_test(diff_series.dropna(), p_threshold):\n",
        "                transformed = diff_series\n",
        "\n",
        "        # Если ничего не сработало → просто diff\n",
        "        if transformed is None:\n",
        "            transformed = col_data.diff()\n",
        "\n",
        "        df[col] = transformed\n",
        "\n",
        "    # 3. Удаляем первые NaN после разностей\n",
        "    df = df.dropna()\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "e30lB5rAQIXc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# --- быстрый тест через автокорреляцию\n",
        "def is_stationary_fast(series, threshold=0.95):\n",
        "    \"\"\"Быстрая проверка стационарности через автокорреляцию\"\"\"\n",
        "    series = series.dropna()\n",
        "    if len(series) < 10:\n",
        "        return True\n",
        "    corr = series.autocorr(lag=1)\n",
        "    return abs(corr) < threshold\n",
        "\n",
        "# --- ADF тест с обрезкой длины\n",
        "def adf_test(series, p_threshold=0.05, max_len=1000):\n",
        "    \"\"\"Проверка стационарности ряда через ADF\"\"\"\n",
        "    series = series.dropna()\n",
        "    if len(series) > max_len:\n",
        "        series = series.tail(max_len)\n",
        "    if series.nunique() < 2:\n",
        "        return False\n",
        "    try:\n",
        "        result = adfuller(series, autolag=\"AIC\")\n",
        "        p_value = result[1]\n",
        "        t_test = result[0] < result[4][\"5%\"]\n",
        "        return p_value < p_threshold and t_test\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# --- обработка одной колонки\n",
        "def process_column(col_data, p_threshold=0.05):\n",
        "    col_data = col_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "    if len(col_data) < 10:\n",
        "        return col_data  # слишком мало данных\n",
        "\n",
        "    # быстрый фильтр\n",
        "    if is_stationary_fast(col_data):\n",
        "        return col_data\n",
        "\n",
        "    # ADF-проверка\n",
        "    if not adf_test(col_data, p_threshold):\n",
        "        # пробуем преобразования\n",
        "        transformed = None\n",
        "\n",
        "        # log\n",
        "        if (col_data > 0).all():\n",
        "            log_series = np.log(col_data)\n",
        "            if adf_test(log_series, p_threshold):\n",
        "                transformed = log_series\n",
        "            else:\n",
        "                log_diff = np.log(col_data).diff()\n",
        "                if adf_test(log_diff, p_threshold):\n",
        "                    transformed = log_diff\n",
        "\n",
        "        # diff\n",
        "        if transformed is None:\n",
        "            diff_series = col_data.diff()\n",
        "            if adf_test(diff_series, p_threshold):\n",
        "                transformed = diff_series\n",
        "\n",
        "        if transformed is None:\n",
        "            transformed = col_data.diff()\n",
        "\n",
        "        return transformed.dropna()\n",
        "\n",
        "    return col_data\n",
        "\n",
        "# --- главная функция\n",
        "def make_stationary(data, p_threshold=0.05, n_jobs=-1):\n",
        "    \"\"\"\n",
        "    Проверяет все признаки на стационарность и приводит их к стационарному виду.\n",
        "    data - DataFrame с фичами\n",
        "    \"\"\"\n",
        "    df = data.copy()\n",
        "\n",
        "    results = Parallel(n_jobs=n_jobs)(\n",
        "        delayed(process_column)(df[col], p_threshold) for col in df.columns\n",
        "    )\n",
        "\n",
        "    df = pd.concat(results, axis=1)\n",
        "    df.columns = data.columns\n",
        "    df = df.dropna()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "3b1872DVcKS_"
      },
      "outputs": [],
      "source": [
        "# from statsmodels.tsa.stattools import adfuller\n",
        "# import numpy as np\n",
        "\n",
        "# non_stationaries = []\n",
        "\n",
        "# for col in df_stationary.columns:\n",
        "#     # Replace infinite values with NaN and drop NaN values for the current column\n",
        "#     col_data = df_stationary[col].replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "#     if col_data.nunique() > 1:  # Проверка на различные значения в столбце\n",
        "#         # Ensure there are enough data points after dropping NaNs for the test\n",
        "#         if len(col_data) > 0:\n",
        "#             try:\n",
        "#                 dftest = adfuller(col_data.values)\n",
        "#                 p_value = dftest[1]\n",
        "#                 # Check if the test statistic is less than the 1% critical value\n",
        "#                 t_test = dftest[0] < dftest[4][\"1%\"]\n",
        "#                 if p_value > 0.05 or not t_test:\n",
        "#                     non_stationaries.append(col)\n",
        "#             except ValueError:\n",
        "#                  # Handle cases where adfuller might still fail (e.g., not enough variation)\n",
        "#                  print(f\"Could not perform ADF test on column {col}\")\n",
        "\n",
        "# print(f\"Non-Stationary Features Found: {len(non_stationaries)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9N5SdHwsa4x"
      },
      "source": [
        "### EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "qPLd714Lsgq-"
      },
      "outputs": [],
      "source": [
        "# Function for detecting outliers in a dataframe\n",
        "# Displays boxplots and a table with outlier information\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def detect_outliers(dataframe):\n",
        "    outlier_table = pd.DataFrame(columns=['Column', 'Outlier Count', 'Outlier Percentage'])  # Creating a DataFrame to store outlier information\n",
        "\n",
        "    for column in dataframe.columns:\n",
        "        if dataframe[column].dtype != 'object' and len(dataframe[column].unique()) == 2:  # Checking for columns with binary values\n",
        "            print(f\"No outliers in column '{column}' as it has binary values.\")  # Printing a message indicating binary values\n",
        "            outlier_table = pd.concat([outlier_table,\n",
        "                                       pd.DataFrame({'Column': [column],\n",
        "                                       'Outlier Count': ['NaN'],\n",
        "                                       'Outlier Percentage': ['NaN']})],\n",
        "                                       ignore_index=True)  # Updating the outlier table with binary value information\n",
        "            print('*' * 75)\n",
        "            print()\n",
        "            continue  # Skipping to the next iteration if the column has binary values\n",
        "\n",
        "        # skipping the object type\n",
        "        if dataframe[column].dtype == 'object':\n",
        "            break\n",
        "\n",
        "        q1 = dataframe[column].quantile(0.25)  # Calculating the first quartile\n",
        "        q3 = dataframe[column].quantile(0.75)  # Calculating the third quartile\n",
        "        iqr = q3 - q1  # Calculating the interquartile range\n",
        "        lower_bound = q1 - 1.5 * iqr\n",
        "        upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "        # Counting the number of outliers\n",
        "        outliers = dataframe[(dataframe[column] < lower_bound) | (dataframe[column] > upper_bound)]\n",
        "        num_outliers = len(outliers)\n",
        "        column_len = len(dataframe[column])\n",
        "\n",
        "        if num_outliers == 0:\n",
        "            print(f\"No outliers in column '{column}'.\")\n",
        "            outlier_table = pd.concat([outlier_table,\n",
        "                                       pd.DataFrame({'Column': [column],\n",
        "                                                    'Outlier Count': [0],\n",
        "                                                    'Outlier Percentage': [0]})],\n",
        "                                                    ignore_index=True)  # Updating the outlier table with outlier count\n",
        "        else:\n",
        "            print(f\"Outliers in column '{column}':\")\n",
        "            print(f\"Outlier Count: {num_outliers}\")\n",
        "            print(f\"Outlier Percentage of total observations: {(num_outliers / column_len) * 100:.2f}%\")  # Calculating and displaying outlier percentage\n",
        "            print(\"Outlier Values:\", \", \".join(outliers[column].astype(str)))\n",
        "\n",
        "            outlier_table = pd.concat([outlier_table,\n",
        "                                       pd.DataFrame({'Column': [column],\n",
        "                                       'Outlier Count': [num_outliers],\n",
        "                                       'Outlier Percentage': [(num_outliers / column_len) * 100]})],\n",
        "                                       ignore_index=True)  # Updating the outlier table with outlier information\n",
        "\n",
        "            # Plotting the boxplot with outliers\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "            sns.boxplot(data=dataframe, x=column, ax=ax)\n",
        "            ax.set_title(f\"Outlier Plot for column '{column}'\")\n",
        "            plt.show()\n",
        "\n",
        "        print('*' * 75)\n",
        "        print()\n",
        "\n",
        "    display(outlier_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWXn4rwwsh1y",
        "outputId": "e3eae784-507d-4b14-8fdf-95a5651be6b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: phik in /usr/local/lib/python3.12/dist-packages (0.12.5)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from phik) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.12/dist-packages (from phik) (1.16.2)\n",
            "Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.12/dist-packages (from phik) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.12/dist-packages (from phik) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.12/dist-packages (from phik) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.1->phik) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.1->phik) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2.3->phik) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Correlation analysis on a dataframe with a target feature using some specified correlation types\n",
        "\n",
        "!pip install phik\n",
        "from phik import phik_matrix\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "def correlation_analysis(dataframe, target_feature, correlation_types=['phik'], apply_abs=False):\n",
        "    target_column = dataframe[target_feature] # Target feature\n",
        "    correlation_data = [] # List to store correlations\n",
        "    interval_cols = [col for col in dataframe.columns if col != target_feature] # Set interval columns for phik\n",
        "\n",
        "    # Calculate correlation coefficients with the target feature for each column and specified correlation types\n",
        "    for column in dataframe.columns:\n",
        "        if column != target_feature:\n",
        "            for corr_type in correlation_types:\n",
        "                corr_value = None\n",
        "\n",
        "                if corr_type == 'pearson':\n",
        "                    corr_value = stats.pearsonr(target_column, dataframe[column])[0]\n",
        "                elif corr_type == 'spearman':\n",
        "                    corr_value = stats.spearmanr(target_column, dataframe[column]).correlation\n",
        "                elif corr_type == 'kendall':\n",
        "                    corr_value = stats.kendalltau(target_column, dataframe[column]).correlation\n",
        "                elif corr_type == 'phik':\n",
        "                    corr_value = phik_matrix(dataframe, interval_cols=interval_cols)[target_feature][column]\n",
        "                # Apply absolute value, if specified\n",
        "                if corr_value is not None and apply_abs:\n",
        "                  corr_value = abs(corr_value)\n",
        "                correlation_data.append((column, corr_type, corr_value))\n",
        "\n",
        "    correlation_df = pd.DataFrame(correlation_data, columns=['Column', 'Correlation Type', 'Correlation Value'])  # Create DataFrame\n",
        "    correlation_df_sorted = correlation_df.pivot(index='Column', columns='Correlation Type', values='Correlation Value')\n",
        "    correlation_df_sorted = correlation_df_sorted[correlation_types] # Keep only specified correlation types\n",
        "    correlation_df_sorted = correlation_df_sorted.sort_values(by=correlation_types, ascending=False) # Sort the data by specified correlation types\n",
        "\n",
        "\n",
        "    # Correlation plot\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=len(correlation_types), figsize=(8 * len(correlation_types), 6))\n",
        "\n",
        "    for i, corr_type in enumerate(correlation_types):\n",
        "        corr_with_target = correlation_df_sorted[corr_type]\n",
        "        corr_with_target_sorted = corr_with_target.sort_values(ascending=True) # Sort the data\n",
        "\n",
        "        # Set plot parameters\n",
        "        sns.barplot(data=corr_with_target_sorted.reset_index(), x='Column', y=corr_type, ax=axes[i], color='dodgerblue')\n",
        "\n",
        "\n",
        "        axes[i].set_xlabel('Features')\n",
        "        axes[i].set_ylabel('Correlation')\n",
        "        axes[i].set_title(corr_type)\n",
        "        axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=75)\n",
        "    plt.tight_layout(pad=1)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # Top 2 features with the highest correlation for each specified correlation type\n",
        "    top_columns = {}\n",
        "    for corr_type in correlation_types:\n",
        "        sorted_columns = correlation_df_sorted[corr_type].abs().sort_values(ascending=False)\n",
        "        top_columns[corr_type] = sorted_columns.index[:2].tolist()\n",
        "\n",
        "    # Display correlation table\n",
        "    print(f\"Correlation table with target feature '{target_feature}':\")\n",
        "    display(correlation_df_sorted)\n",
        "\n",
        "    # Display the top 2 features with the highest correlation for each correlation type\n",
        "    for corr_type in correlation_types:\n",
        "        print()\n",
        "        print(f\"Top 2 features with highest correlation ({corr_type.capitalize()}):\", top_columns[corr_type])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_MzBAGTY46x",
        "outputId": "8ac6d7e9-0ff0-4aaa-e73a-f5a8cf4a2640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: phik in /usr/local/lib/python3.12/dist-packages (0.12.5)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from phik) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.12/dist-packages (from phik) (1.16.2)\n",
            "Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.12/dist-packages (from phik) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.12/dist-packages (from phik) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.12/dist-packages (from phik) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->phik) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.1->phik) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.1->phik) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2.3->phik) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Correlation analysis on a dataframe with a target feature using some specified correlation types\n",
        "\n",
        "!pip install phik\n",
        "from phik import phik_matrix\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "def correlation_analysis(dataframe, target_feature, correlation_types=['phik'], apply_abs=False):\n",
        "    target_column = dataframe[target_feature] # Target feature\n",
        "    correlation_data = [] # List to store correlations\n",
        "    interval_cols = [col for col in dataframe.columns if col != target_feature] # Set interval columns for phik\n",
        "\n",
        "    # Calculate correlation coefficients with the target feature for each column and specified correlation types\n",
        "    for column in dataframe.columns:\n",
        "        if column != target_feature:\n",
        "            for corr_type in correlation_types:\n",
        "                corr_value = None\n",
        "\n",
        "                if corr_type == 'pearson':\n",
        "                    corr_value = stats.pearsonr(target_column, dataframe[column])[0]\n",
        "                elif corr_type == 'spearman':\n",
        "                    corr_value = stats.spearmanr(target_column, dataframe[column]).correlation\n",
        "                elif corr_type == 'kendall':\n",
        "                    corr_value = stats.kendalltau(target_column, dataframe[column]).correlation\n",
        "                elif corr_type == 'phik':\n",
        "                    corr_value = phik_matrix(dataframe, interval_cols=interval_cols)[target_feature][column]\n",
        "                # Apply absolute value, if specified\n",
        "                if corr_value is not None and apply_abs:\n",
        "                  corr_value = abs(corr_value)\n",
        "                correlation_data.append((column, corr_type, corr_value))\n",
        "\n",
        "    correlation_df = pd.DataFrame(correlation_data, columns=['Column', 'Correlation Type', 'Correlation Value'])  # Create DataFrame\n",
        "    correlation_df_sorted = correlation_df.pivot(index='Column', columns='Correlation Type', values='Correlation Value')\n",
        "    correlation_df_sorted = correlation_df_sorted[correlation_types] # Keep only specified correlation types\n",
        "    correlation_df_sorted = correlation_df_sorted.sort_values(by=correlation_types, ascending=False) # Sort the data by specified correlation types\n",
        "\n",
        "\n",
        "    # Correlation plot\n",
        "    if len(correlation_types) == 1:\n",
        "        fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8, 6))\n",
        "        axes = [axes] # Wrap the single axes object in a list for consistent indexing\n",
        "    else:\n",
        "        fig, axes = plt.subplots(nrows=1, ncols=len(correlation_types), figsize=(8 * len(correlation_types), 6))\n",
        "\n",
        "\n",
        "    for i, corr_type in enumerate(correlation_types):\n",
        "        corr_with_target = correlation_df_sorted[corr_type]\n",
        "        corr_with_target_sorted = corr_with_target.sort_values(ascending=True) # Sort the data\n",
        "\n",
        "        # Set plot parameters\n",
        "        sns.barplot(data=corr_with_target_sorted.reset_index(), x='Column', y=corr_type, ax=axes[i], color='dodgerblue')\n",
        "\n",
        "\n",
        "        axes[i].set_xlabel('Features')\n",
        "        axes[i].set_ylabel('Correlation')\n",
        "        axes[i].set_title(corr_type)\n",
        "        axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=75)\n",
        "    plt.tight_layout(pad=1)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # Top 2 features with the highest correlation for each specified correlation type\n",
        "    top_columns = {}\n",
        "    for corr_type in correlation_types:\n",
        "        sorted_columns = correlation_df_sorted[corr_type].abs().sort_values(ascending=False)\n",
        "        top_columns[corr_type] = sorted_columns.index[:2].tolist()\n",
        "\n",
        "    # Display correlation table\n",
        "    print(f\"Correlation table with target feature '{target_feature}':\")\n",
        "    display(correlation_df_sorted)\n",
        "\n",
        "    # Display the top 2 features with the highest correlation for each correlation type\n",
        "    for corr_type in correlation_types:\n",
        "        print()\n",
        "        print(f\"Top 2 features with highest correlation ({corr_type.capitalize()}):\", top_columns[corr_type])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "LYfn6Uf0ZgQK"
      },
      "outputs": [],
      "source": [
        "# Function to find multicollinearity and print correlation matrix\n",
        "# !pip install phik\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from phik import phik_matrix\n",
        "\n",
        "def find_multicollinearity(dataframe, methods=['phik'], threshold=0.8):\n",
        "    # List to store all multicollinear tables\n",
        "    multicollinear_tables = []\n",
        "\n",
        "    # Iterate through each method in the list of methods\n",
        "    for method in methods:\n",
        "        # Convert method to lowercase\n",
        "        method = method.lower()\n",
        "\n",
        "        # Calculate correlation matrix using specified sort method\n",
        "        if method in ['pearson', 'kendall', 'spearman']:\n",
        "            corr_matrix = dataframe.corr(method=method).abs()\n",
        "        elif method == 'phik':\n",
        "            interval_cols = [col for col in dataframe.columns]\n",
        "            corr_matrix = phik_matrix(dataframe, interval_cols=interval_cols)\n",
        "        else:\n",
        "            print(f\"Invalid method: {method}\")\n",
        "            continue\n",
        "\n",
        "        # Exclude correlation of a variable with itself\n",
        "        np.fill_diagonal(corr_matrix.values, np.nan)\n",
        "\n",
        "        # Create a larger figure size based on the number of features\n",
        "        n = corr_matrix.shape[0]\n",
        "        fig_width = 6 + n * 0.5\n",
        "        fig_height = 4 + n * 0.3\n",
        "\n",
        "        # Plot correlation matrix as heatmap with adjusted figure size\n",
        "        plt.figure(figsize=(fig_width, fig_height))\n",
        "        sns.heatmap(corr_matrix, cmap='coolwarm', annot=True, fmt=\".2f\", mask=np.isnan(corr_matrix))\n",
        "        plt.title(f\"Correlation Matrix ({method})\")\n",
        "        plt.show()\n",
        "\n",
        "        # Initialize an empty list to store multicollinear features\n",
        "        multicollinear_table = []\n",
        "\n",
        "        # Iterate through each pair of multicollinear features and their correlation percentages\n",
        "        for i in range(n):\n",
        "            for j in range(i+1, n):\n",
        "                # Check if the correlation between the two features is above the threshold\n",
        "                if corr_matrix.iloc[i, j] > threshold:\n",
        "                    feature1 = corr_matrix.columns[i]\n",
        "                    feature2 = corr_matrix.columns[j]\n",
        "                    # Append the pair of multicollinear features and their correlation percentage to the list\n",
        "                    multicollinear_table.append({'Feature 1': feature1, 'Feature 2': feature2, 'Correlation': corr_matrix.iloc[i, j]})\n",
        "\n",
        "        # Create a dataframe from the list of multicollinear features\n",
        "        multicollinear_table = pd.DataFrame(multicollinear_table)\n",
        "\n",
        "        if not multicollinear_table.empty:\n",
        "            # Sort the multicollinear table by correlation in descending order\n",
        "            multicollinear_table = multicollinear_table.sort_values(by='Correlation', ascending=False)\n",
        "            # Append the multicollinear table to the list of multicollinear tables\n",
        "            multicollinear_tables.append((method, multicollinear_table))\n",
        "\n",
        "    # Print all multicollinear tables\n",
        "    if multicollinear_tables:\n",
        "        for method, table in multicollinear_tables:\n",
        "            print(f\"\\nMulticollinearity Table ({method})\")\n",
        "            display(table)\n",
        "    else:\n",
        "        print(\"\\nNo features with high multicollinearity!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "izyyBT0HDIOO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqkFgymNioLr"
      },
      "source": [
        "## Data extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKRwH-ZYiqvp"
      },
      "outputs": [],
      "source": [
        "# Data extraction\n",
        "symbol = 'BTCUSDT'\n",
        "interval = '1m'\n",
        "start_date = '2022-09'\n",
        "end_date = '2025-09'\n",
        "\n",
        "data_klines = download_klines(symbol, interval, start_date, end_date)\n",
        "data = data_klines.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKq3f65CZnEE"
      },
      "outputs": [],
      "source": [
        "# check and remove duplicates in index\n",
        "data = data[~data.index.duplicated(keep='first')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrXMBhSdz3fj"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkYvk-2bqAV_"
      },
      "outputs": [],
      "source": [
        "data.columns = data.columns.str.lower()\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aq_xIUIMemX"
      },
      "outputs": [],
      "source": [
        "plt.style.use('dark_background')\n",
        "fig, ax = plt.subplots(figsize=(19,6))\n",
        "plt.plot(data.index, data['close'])\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Time')\n",
        "plt.title('Price Change')\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB4y-MGmDNAo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiCXcol6ZaCu"
      },
      "source": [
        "## Candle patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdpUEaJhYG1-"
      },
      "outputs": [],
      "source": [
        "data = detect_candlestick_patterns(data)\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def detect_candlestick_patterns_v2(df,\n",
        "    atr_period=14,\n",
        "    doji_th=0.15,\n",
        "    hammer_lower_mult=2.0,\n",
        "    hammer_upper_mult=0.3,\n",
        "    small_body_factor=0.4,\n",
        "    min_body_atr=0.15,        # минимальный размер тела в долях ATR\n",
        "    vol_ma_period=20,\n",
        "    vol_mult_bonus=1.2,       # бонус к силе, если объём > vol_ma * vol_mult_bonus\n",
        "    pattern_weights=None      # можно задать веса для отдельных паттернов\n",
        "):\n",
        "    \"\"\"\n",
        "    Возвращает df с колонками:\n",
        "      'Pattern'          — название паттерна (или NaN)\n",
        "      'Signal'           — 1 (бычий), -1 (медвежий), 0 (нет сигнала)\n",
        "      'Signal_strength'  — сила сигнала (0–5)\n",
        "      'ATR'              — значение среднего истинного диапазона\n",
        "\n",
        "    Требует DataFrame с колонками Open, High, Low, Close (+ Volume опционально).\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Веса паттернов ---\n",
        "    if pattern_weights is None:\n",
        "        pattern_weights = {\n",
        "            'bullish_engulfing': 1.2,\n",
        "            'bearish_engulfing': 1.2,\n",
        "            'piercing_line': 1.0,\n",
        "            'dark_cloud': 1.0,\n",
        "            'hammer': 0.9,\n",
        "            'inverted_hammer': 0.9,\n",
        "            'morning_star': 1.3,\n",
        "            'evening_star': 1.3,\n",
        "            'three_white_soldiers': 1.4,\n",
        "            'three_black_crows': 1.4,\n",
        "            'harami_cross': 0.8\n",
        "        }\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # --- Нормализация имен колонок ---\n",
        "    colmap = {}\n",
        "    for name in ['Open','High','Low','Close','Volume']:\n",
        "        if name in df.columns:\n",
        "            colmap[name] = name\n",
        "        elif name.lower() in df.columns:\n",
        "            colmap[name] = name.lower()\n",
        "        else:\n",
        "            colmap[name] = None\n",
        "\n",
        "    if colmap['Open'] is None or colmap['High'] is None or colmap['Low'] is None or colmap['Close'] is None:\n",
        "        raise ValueError(\"DataFrame must contain Open/High/Low/Close (case-insensitive)\")\n",
        "\n",
        "    O = df[colmap['Open']].astype(float)\n",
        "    H = df[colmap['High']].astype(float)\n",
        "    L = df[colmap['Low']].astype(float)\n",
        "    C = df[colmap['Close']].astype(float)\n",
        "    V = df[colmap['Volume']] if colmap['Volume'] is not None else None\n",
        "\n",
        "    prev_O = O.shift(1)\n",
        "    prev_H = H.shift(1)\n",
        "    prev_L = L.shift(1)\n",
        "    prev_C = C.shift(1)\n",
        "    pre_prev_O = O.shift(2)\n",
        "    pre_prev_C = C.shift(2)\n",
        "\n",
        "    # --- ATR ---\n",
        "    tr = pd.concat([\n",
        "        (H - L).abs(),\n",
        "        (H - prev_C).abs(),\n",
        "        (L - prev_C).abs()\n",
        "    ], axis=1).max(axis=1)\n",
        "    atr = tr.rolling(atr_period, min_periods=1).mean()\n",
        "\n",
        "    # --- Расчёты тела и теней ---\n",
        "    body = C - O\n",
        "    body_abs = body.abs()\n",
        "    upper_shadow = H - np.maximum(O, C)\n",
        "    lower_shadow = np.minimum(O, C) - L\n",
        "    rng = (H - L).replace(0, np.nan)\n",
        "    body_pct_of_range = body_abs / rng\n",
        "\n",
        "    # --- Volume MA ---\n",
        "    if V is not None:\n",
        "        vol_ma = V.rolling(vol_ma_period, min_periods=1).mean()\n",
        "    else:\n",
        "        vol_ma = None\n",
        "\n",
        "    # --- Минимальный размер тела ---\n",
        "    min_body = min_body_atr * atr\n",
        "\n",
        "    # --- Doji ---\n",
        "    is_doji = (body_abs <= doji_th * rng) | (rng == 0)\n",
        "\n",
        "    # --- Hammer / Inverted Hammer ---\n",
        "    hammer = (\n",
        "        (lower_shadow >= hammer_lower_mult * body_abs) &\n",
        "        (upper_shadow <= hammer_upper_mult * body_abs) &\n",
        "        (body_pct_of_range <= 0.5) &\n",
        "        (body_abs >= min_body)\n",
        "    )\n",
        "\n",
        "    inverted_hammer = (\n",
        "        (upper_shadow >= hammer_lower_mult * body_abs) &\n",
        "        (lower_shadow <= hammer_upper_mult * body_abs) &\n",
        "        (body_pct_of_range <= 0.5) &\n",
        "        (body_abs >= min_body)\n",
        "    )\n",
        "\n",
        "    # --- Engulfing ---\n",
        "    prev_body_abs = (prev_C - prev_O).abs()\n",
        "    bullish_engulfing = (\n",
        "        (prev_C < prev_O) &\n",
        "        (C > O) &\n",
        "        (O <= prev_C) & (C >= prev_O) &\n",
        "        (body_abs > prev_body_abs) &\n",
        "        (body_abs >= min_body)\n",
        "    )\n",
        "\n",
        "    bearish_engulfing = (\n",
        "        (prev_C > prev_O) &\n",
        "        (C < O) &\n",
        "        (O >= prev_C) & (C <= prev_O) &\n",
        "        (body_abs > prev_body_abs) &\n",
        "        (body_abs >= min_body)\n",
        "    )\n",
        "\n",
        "    # --- Piercing / Dark Cloud ---\n",
        "    prev_mid = (prev_O + prev_C) / 2.0\n",
        "    piercing = (\n",
        "        (prev_C < prev_O) &\n",
        "        (O < prev_L) &\n",
        "        (C > prev_mid) &\n",
        "        (C < prev_O) &\n",
        "        (body_abs >= min_body)\n",
        "    )\n",
        "\n",
        "    dark_cloud = (\n",
        "        (prev_C > prev_O) &\n",
        "        (O > prev_H) &\n",
        "        (C < prev_mid) &\n",
        "        (C > prev_O) &\n",
        "        (body_abs >= min_body)\n",
        "    )\n",
        "\n",
        "    # --- Morning / Evening Star ---\n",
        "    pre_prev_body_abs = (pre_prev_C - pre_prev_O).abs()\n",
        "\n",
        "    morning_star = (\n",
        "        (pre_prev_C < pre_prev_O) &\n",
        "        (prev_body_abs <= small_body_factor * pre_prev_body_abs) &\n",
        "        (C > O) &\n",
        "        (C > (pre_prev_O + pre_prev_C) / 2.0) &\n",
        "        (body_abs >= min_body)\n",
        "    )\n",
        "\n",
        "    evening_star = (\n",
        "        (pre_prev_C > pre_prev_O) &\n",
        "        (prev_body_abs <= small_body_factor * pre_prev_body_abs) &\n",
        "        (C < O) &\n",
        "        (C < (pre_prev_O + pre_prev_C) / 2.0) &\n",
        "        (body_abs >= min_body)\n",
        "    )\n",
        "\n",
        "    # --- Three White Soldiers / Three Black Crows ---\n",
        "    o0, o1, o2 = O.shift(2), O.shift(1), O\n",
        "    c0, c1, c2 = C.shift(2), C.shift(1), C\n",
        "\n",
        "    tws = (\n",
        "        (c0 > o0) & (c1 > o1) & (c2 > o2) &\n",
        "        (c2 > c1) & (c1 > c0) &\n",
        "        (o1 > o0) & (o2 > o1) &\n",
        "        ((c0 - o0) >= min_body) &\n",
        "        ((c1 - o1) >= min_body) &\n",
        "        ((c2 - o2) >= min_body)\n",
        "    )\n",
        "\n",
        "    tbc = (\n",
        "        (c0 < o0) & (c1 < o1) & (c2 < o2) &\n",
        "        (c2 < c1) & (c1 < c0) &\n",
        "        (o1 < o0) & (o2 < o1) &\n",
        "        ((o0 - c0) >= min_body) &\n",
        "        ((o1 - c1) >= min_body) &\n",
        "        ((o2 - c2) >= min_body)\n",
        "    )\n",
        "\n",
        "    # --- Harami Cross ---\n",
        "    prev_body_top = np.maximum(prev_O, prev_C)\n",
        "    prev_body_bot = np.minimum(prev_O, prev_C)\n",
        "    harami_cross = (\n",
        "        is_doji &\n",
        "        (H < prev_body_top) &\n",
        "        (L > prev_body_bot) &\n",
        "        (prev_body_abs >= 0.5 * rng.shift(1).fillna(0))\n",
        "    )\n",
        "\n",
        "    # --- Сбор паттернов ---\n",
        "    n = len(df)\n",
        "    pattern = pd.Series([None]*n, index=df.index, dtype=\"object\")\n",
        "    signal = pd.Series(0, index=df.index, dtype=\"int\")\n",
        "    strength = pd.Series(0.0, index=df.index, dtype=\"float\")\n",
        "\n",
        "    def add_pattern(mask, name, dir_sign):\n",
        "        w = pattern_weights.get(name, 1.0)\n",
        "        base = (body_abs / atr).clip(lower=0).fillna(0)\n",
        "        s = base * w\n",
        "\n",
        "        if vol_ma is not None:\n",
        "            vol_bonus = (V > vol_ma * vol_mult_bonus).astype(float)\n",
        "            s *= (1.0 + 0.3 * vol_bonus)\n",
        "\n",
        "        idx = mask.fillna(False)\n",
        "        replace_idx = idx & (s > strength)\n",
        "        pattern.loc[replace_idx] = name\n",
        "        signal.loc[replace_idx] = dir_sign\n",
        "        strength.loc[replace_idx] = s.loc[replace_idx]\n",
        "\n",
        "    # --- Добавляем все паттерны ---\n",
        "    add_pattern(bullish_engulfing, 'bullish_engulfing', 1)\n",
        "    add_pattern(bearish_engulfing, 'bearish_engulfing', -1)\n",
        "    add_pattern(piercing, 'piercing_line', 1)\n",
        "    add_pattern(dark_cloud, 'dark_cloud', -1)\n",
        "    add_pattern(hammer, 'hammer', 1)\n",
        "    add_pattern(inverted_hammer, 'inverted_hammer', -1)\n",
        "    add_pattern(morning_star, 'morning_star', 1)\n",
        "    add_pattern(evening_star, 'evening_star', -1)\n",
        "    add_pattern(tws, 'three_white_soldiers', 1)\n",
        "    add_pattern(tbc, 'three_black_crows', -1)\n",
        "    add_pattern(harami_cross, 'harami_cross', 0)\n",
        "\n",
        "    # --- Постобработка ---\n",
        "    strength = strength.fillna(0.0).clip(lower=0.0, upper=5.0)\n",
        "\n",
        "    df['Pattern'] = pattern\n",
        "    df['Signal'] = signal\n",
        "    df['Signal_strength'] = strength\n",
        "    df['ATR'] = atr\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "data_v2 = data.copy()\n",
        "data_v2 = detect_candlestick_patterns_v2(data_v2)\n",
        "data_v2.info()"
      ],
      "metadata": {
        "id": "aR_KANwsonEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDqfUQA_P2OX"
      },
      "outputs": [],
      "source": [
        "plot_random_pattern(data, 'doji', 'Doji')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_random_pattern(data_v2, 'doji', 'Doji')"
      ],
      "metadata": {
        "id": "mXPYFkXubVhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TorzmSmGZx5p"
      },
      "outputs": [],
      "source": [
        "# display a random pattern\n",
        "plot_random_pattern(data, 'hammer', 'hammer')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_random_pattern(data_v2, 'hammer', 'hammer')"
      ],
      "metadata": {
        "id": "Au7Wx_pDcSrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA1Px08Gb6GW"
      },
      "outputs": [],
      "source": [
        "plot_random_pattern(data, 'inverted_hammer', 'inverted_hammer')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_random_pattern(data_v2, 'inverted_hammer', 'inverted_hammer')"
      ],
      "metadata": {
        "id": "MG7mpzsscc9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5zD0o2ubLIJ"
      },
      "outputs": [],
      "source": [
        "plot_random_pattern(data, 'bullish_engulfing', 'bullish_engulfing')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dITtYZPRQHgd"
      },
      "outputs": [],
      "source": [
        "plot_random_pattern(data, 'bearish_engulfing', 'bearish_engulfing')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfnDNNazQvQc"
      },
      "outputs": [],
      "source": [
        "plot_random_pattern(data, 'piercing_line', 'piercing_line')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBAeY6s_R_fW"
      },
      "outputs": [],
      "source": [
        "plot_random_pattern(data, 'dark_cloud', 'dark_cloud')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsbZEPDqaga-"
      },
      "outputs": [],
      "source": [
        "plot_random_pattern(data, 'three_white_soldiers', 'three_white_soldiers')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4_dJleDRtkM"
      },
      "outputs": [],
      "source": [
        "plot_random_pattern(data, 'three_black_crows', 'three_black_crows')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gevBAokbJsW"
      },
      "outputs": [],
      "source": [
        "plot_random_pattern(data, 'harami_cross', 'harami_cross')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c99UX01zSH2I"
      },
      "outputs": [],
      "source": [
        "plot_random_pattern(data, 'bearish_harami', 'bearish_harami')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZhGeCo4bM9b"
      },
      "outputs": [],
      "source": [
        "plot_random_pattern(data, 'morning_star', 'morning_star')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuMFptrbRRld"
      },
      "outputs": [],
      "source": [
        "plot_random_pattern(data, 'evening_star', 'evening_star')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWLq0-n5RbU2"
      },
      "source": [
        "Patterns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut5EKaHKo83E"
      },
      "outputs": [],
      "source": [
        "# Считаем количество True для всех свечных паттернов\n",
        "pattern_cols = [\n",
        "    \"doji\", \"hammer\", \"inverted_hammer\", \"three_white_soldiers\", \"three_black_crows\",\n",
        "    \"bullish_engulfing\", \"bearish_engulfing\", \"dark_cloud\", \"harami_cross\",\n",
        "    \"morning_star\", \"evening_star\", \"piercing_line\", \"bearish_harami\"\n",
        "]\n",
        "\n",
        "pattern_counts = {col: int(data[col].sum()) for col in pattern_cols}\n",
        "\n",
        "# Печатаем статистику\n",
        "for col, count in pattern_counts.items():\n",
        "    print(f\"{col.replace('_', ' ').title()} patterns: {count}\")\n",
        "\n",
        "print(f\"\\nTotal patterns: {sum(pattern_counts.values())}\")\n",
        "\n",
        "# Удаляем колонки, где нет ни одного сигнала\n",
        "for col, count in pattern_counts.items():\n",
        "    if count == 0:\n",
        "        data.drop(columns=[col], inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YjY6P5sJYV0_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou0F-VJW0YSI"
      },
      "source": [
        "# Backtesting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY6QH57onM2Y"
      },
      "outputs": [],
      "source": [
        "df = data.copy()\n",
        "\n",
        "# 1) Переименовываем только OHLC(V) в формат, который требует backtesting.py\n",
        "rename_map = {}\n",
        "if 'open' in df.columns:\n",
        "    rename_map['open'] = 'Open'\n",
        "if 'high' in df.columns:\n",
        "    rename_map['high'] = 'High'\n",
        "if 'low' in df.columns:\n",
        "    rename_map['low'] = 'Low'\n",
        "if 'close' in df.columns:\n",
        "    rename_map['close'] = 'Close'\n",
        "if 'volume' in df.columns:\n",
        "    rename_map['volume'] = 'Volume'\n",
        "\n",
        "df = df.rename(columns=rename_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLwO3rHwqEGg"
      },
      "outputs": [],
      "source": [
        "if not isinstance(df.index, pd.DatetimeIndex):\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "df = df.sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBseg8RNqJWj"
      },
      "outputs": [],
      "source": [
        "bullish_patterns = [\n",
        "    'hammer', 'inverted_hammer', 'bullish_engulfing',\n",
        "    'piercing_line', 'morning_star', 'three_white_soldiers'\n",
        "]\n",
        "bearish_patterns = [\n",
        "    'bearish_engulfing', 'dark_cloud', 'evening_star',\n",
        "    'three_black_crows', 'bearish_harami'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKZ_xbfqqQcZ"
      },
      "outputs": [],
      "source": [
        "# Если каких-то колонок-паттернов нет — создадим их как False (без падения)\n",
        "for col in set(bullish_patterns + bearish_patterns):\n",
        "    if col not in df.columns:\n",
        "        df[col] = False\n",
        "\n",
        "\n",
        "# Формируем одну колонку Signal: 1 = long, -1 = short, 0 = нет сигнала\n",
        "df['Signal'] = 0\n",
        "df.loc[df[bullish_patterns].any(axis=1), 'Signal'] = 1\n",
        "df.loc[df[bearish_patterns].any(axis=1), 'Signal'] = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUQIoUXQqdNR"
      },
      "outputs": [],
      "source": [
        "atr_period = 14\n",
        "df['ATR'] = talib.ATR(df['High'].values, df['Low'].values, df['Close'].values, timeperiod=atr_period)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4bNZS8gqesg"
      },
      "outputs": [],
      "source": [
        "# Удалим строки с NaN в OHLC (backtesting.py требует полные свечи)\n",
        "df = df.dropna(subset=['Open', 'High', 'Low', 'Close'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2_nWJHgsMe9"
      },
      "source": [
        "### Basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3gormKG16QS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import talib\n",
        "from backtesting import Backtest, Strategy\n",
        "\n",
        "# ====== Подготовка DataFrame (подставь свой data) ======\n",
        "# data — DataFrame, который получил после detect_candlestick_patterns(...)\n",
        "df = data.copy()\n",
        "\n",
        "# 1) Переименовываем только OHLC(V) в формат, который требует backtesting.py\n",
        "rename_map = {}\n",
        "if 'open' in df.columns:\n",
        "    rename_map['open'] = 'Open'\n",
        "if 'high' in df.columns:\n",
        "    rename_map['high'] = 'High'\n",
        "if 'low' in df.columns:\n",
        "    rename_map['low'] = 'Low'\n",
        "if 'close' in df.columns:\n",
        "    rename_map['close'] = 'Close'\n",
        "if 'volume' in df.columns:\n",
        "    rename_map['volume'] = 'Volume'\n",
        "\n",
        "df = df.rename(columns=rename_map)\n",
        "\n",
        "# 2) Убедимся, что индекс — DatetimeIndex и отсортирован\n",
        "if not isinstance(df.index, pd.DatetimeIndex):\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "df = df.sort_index()\n",
        "\n",
        "# 3) Проверка обязательных колонок\n",
        "required = {'Open', 'High', 'Low', 'Close'}\n",
        "if not required.issubset(set(df.columns)):\n",
        "    missing = required - set(df.columns)\n",
        "    raise ValueError(f\"DataFrame missing required OHLC columns: {missing}\")\n",
        "\n",
        "# ====== Собираем сигналы (Signal) на основании паттернов ======\n",
        "bullish_patterns = [\n",
        "    'hammer', 'inverted_hammer', 'bullish_engulfing',\n",
        "    'piercing_line', 'morning_star', 'three_white_soldiers'\n",
        "]\n",
        "bearish_patterns = [\n",
        "    'bearish_engulfing', 'dark_cloud', 'evening_star',\n",
        "    'three_black_crows', 'bearish_harami'\n",
        "]\n",
        "\n",
        "# Если каких-то колонок-паттернов нет — создадим их как False (без падения)\n",
        "for col in set(bullish_patterns + bearish_patterns):\n",
        "    if col not in df.columns:\n",
        "        df[col] = False\n",
        "\n",
        "# Формируем одну колонку Signal: 1 = long, -1 = short, 0 = нет сигнала\n",
        "df['Signal'] = 0\n",
        "df.loc[df[bullish_patterns].any(axis=1), 'Signal'] = 1\n",
        "df.loc[df[bearish_patterns].any(axis=1), 'Signal'] = -1\n",
        "\n",
        "# ====== Рассчитываем ATR (TA-Lib) ======\n",
        "atr_period = 14\n",
        "df['ATR'] = talib.ATR(df['High'].values, df['Low'].values, df['Close'].values, timeperiod=atr_period)\n",
        "\n",
        "# Удалим строки с NaN в OHLC (backtesting.py требует полные свечи)\n",
        "df = df.dropna(subset=['Open', 'High', 'Low', 'Close'])\n",
        "\n",
        "# ====== Strategy для backtesting.py ======\n",
        "class PatternATRStrategy(Strategy):\n",
        "    atr_period = atr_period\n",
        "    stop_atr = 0.75\n",
        "    take_atr = 0.75 # можно менять\n",
        "\n",
        "    def init(self):\n",
        "        # вычислим ATR как индикатор (чтобы он был выровнен по индексу)\n",
        "        self.atr = self.I(\n",
        "            lambda H, L, C: talib.ATR(H, L, C, timeperiod=self.atr_period),\n",
        "            self.data.High, self.data.Low, self.data.Close\n",
        "        )\n",
        "        # скопируем Signal в индикатор для удобного доступа\n",
        "        # backtesting.Data позволяет обращаться к дополнительным колонкам через self.data.df\n",
        "        # используем self.I, чтобы получить выровненный массив\n",
        "        self.signal = self.I(lambda s: s.values, self.data.df['Signal'])\n",
        "        self.stop_atr = self.stop_atr\n",
        "        self.take_atr = self.take_atr\n",
        "\n",
        "    def next(self):\n",
        "        atr = self.atr[-1]\n",
        "        sig = int(self.signal[-1])  # 1, -1 или 0\n",
        "        price = self.data.Close[-1]\n",
        "\n",
        "        # если ATR ещё nan — не торгуем\n",
        "        if np.isnan(atr):\n",
        "            return\n",
        "\n",
        "        # Если нет открытой позиции — выставляем ордер по сигналу\n",
        "        if not self.position:\n",
        "            if sig == 1:\n",
        "                sl = price - self.stop_atr * atr\n",
        "                tp = price + self.take_atr * atr\n",
        "                # trade_on_close=True — исполнение по close текущей свечи\n",
        "                self.buy(sl=sl, tp=tp)\n",
        "            elif sig == -1:\n",
        "                sl = price + self.stop_atr * atr\n",
        "                tp = price - self.take_atr * atr\n",
        "                self.sell(sl=sl, tp=tp)\n",
        "        # если позиция открыта, backtesting.py сам отслеживает SL/TP, закрытие не нужно дописывать здесь\n",
        "\n",
        "# ====== Запуск бэктеста ======\n",
        "bt = Backtest(\n",
        "    df,\n",
        "    PatternATRStrategy,\n",
        "    cash=1_000_000,\n",
        "    commission=0.0005,      # пример комиссии\n",
        "    trade_on_close=True,    # вход по close свечи, где обнаружен паттерн\n",
        "    exclusive_orders=True   # одна открытая позиция за раз\n",
        ")\n",
        "\n",
        "stats = bt.run()\n",
        "print(stats)      # сводка метрик\n",
        "# bt.plot(open_browser=False)   # откроет график в jupyter / локально"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ULGci99sQKy"
      },
      "source": [
        "### Indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgnNF-oYBCNP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import talib\n",
        "from backtesting import Backtest, Strategy\n",
        "\n",
        "class PatternIndicatorsStrategy(Strategy):\n",
        "    # --- параметры (подбирай / оптимизируй) ---\n",
        "    atr_period = 14\n",
        "\n",
        "    # трендовые EMAs\n",
        "    ema_fast_period = 50\n",
        "    ema_slow_period = 200\n",
        "    require_trend = True\n",
        "\n",
        "    # подтверждение (breakout confirmation)\n",
        "    require_confirmation = True\n",
        "    confirmation_buf = 0.0005\n",
        "\n",
        "    # объём\n",
        "    use_volume_filter = False\n",
        "    vol_ma_period = 20\n",
        "    vol_mult = 1.15\n",
        "\n",
        "    # S/R proximity\n",
        "    use_sr_filter = False\n",
        "    sr_lookback = 50\n",
        "    sr_atr_mult = 1.0\n",
        "\n",
        "    # минимальный \"вес\" паттерна\n",
        "    min_body_atr = 0.05\n",
        "\n",
        "    # ADX / volatility filters\n",
        "    use_adx = False\n",
        "    adx_period = 14\n",
        "    adx_threshold = 20\n",
        "\n",
        "    # риск-менеджмент\n",
        "    risk_per_trade = 0.005\n",
        "    min_fraction = 0.001\n",
        "    max_fraction = 0.2\n",
        "\n",
        "    # misc\n",
        "    min_atr_ratio = 0.0001\n",
        "\n",
        "    def init(self):\n",
        "        # Ссылка на \"сырые\" данные (pandas DataFrame) — безопасно\n",
        "        self._df = self.data.df\n",
        "\n",
        "        # удостоверься, что необходимые столбцы есть\n",
        "        if not {'High', 'Low', 'Close', 'Open'}.issubset(self._df.columns):\n",
        "            raise ValueError(\"DataFrame must contain 'High','Low','Close','Open' columns\")\n",
        "\n",
        "        # series для индикаторов (pandas Series)\n",
        "        H = self._df['High']\n",
        "        L = self._df['Low']\n",
        "        C = self._df['Close']\n",
        "        O = self._df['Open']\n",
        "        V = self._df['Volume'] if 'Volume' in self._df.columns else None\n",
        "\n",
        "        # индикаторы (через self.I -> выровненные массивы)\n",
        "        self.atr = self.I(lambda H, L, C: talib.ATR(H, L, C, timeperiod=self.atr_period), H, L, C)\n",
        "        self.ema_fast = self.I(talib.EMA, C, self.ema_fast_period)\n",
        "        self.ema_slow = self.I(talib.EMA, C, self.ema_slow_period)\n",
        "\n",
        "        if self.use_adx:\n",
        "            self.adx = self.I(lambda H, L, C: talib.ADX(H, L, C, timeperiod=self.adx_period), H, L, C)\n",
        "        else:\n",
        "            self.adx = None\n",
        "\n",
        "        # volume MA (если есть Volume)\n",
        "        if V is not None and self.use_volume_filter:\n",
        "            self.vol_ma = self.I(lambda vol, period=self.vol_ma_period:\n",
        "                                 pd.Series(vol).rolling(period).mean().values, V)\n",
        "        else:\n",
        "            self.vol_ma = None\n",
        "\n",
        "        # rolling S/R на основе Close\n",
        "        self.roll_min = self.I(lambda c, lookback=self.sr_lookback:\n",
        "                               pd.Series(c).rolling(lookback).min().values, C)\n",
        "        self.roll_max = self.I(lambda c, lookback=self.sr_lookback:\n",
        "                               pd.Series(c).rolling(lookback).max().values, C)\n",
        "\n",
        "        # тело свечи (выровнённый массив)\n",
        "        self.body = self.I(lambda o, c: np.abs(c - o), O, C)\n",
        "\n",
        "        # сигнал из внешней колонки Signal — берем \"сырую\" колонку, её наличие гарантируем в основном коде\n",
        "        if 'Signal' not in self._df.columns:\n",
        "            # если нет — создадим нулевую колонку\n",
        "            self._df['Signal'] = 0\n",
        "        # нет необходимости применять self.I для Signal — используем _df напрямую в next()\n",
        "        # но можно сохранить ссылку:\n",
        "        self._signal_series = self._df['Signal']\n",
        "\n",
        "\n",
        "\n",
        "    def next(self):\n",
        "        i = len(self.data) - 1  # индекс текущей свечи в обработчике\n",
        "\n",
        "        # нужно как минимум 1 предыдущая свеча, если требуется подтверждение\n",
        "        if self.require_confirmation and i < 1:\n",
        "            return\n",
        "\n",
        "        # текущие значения\n",
        "        price = self.data.Close[-1]\n",
        "        atr = self.atr[-1]\n",
        "\n",
        "        if np.isnan(atr) or np.isnan(price):\n",
        "            return\n",
        "\n",
        "        # базовая волатильность\n",
        "        if (atr / price) < self.min_atr_ratio:\n",
        "            return\n",
        "\n",
        "        # получаем сигнал (в предыдущей свече при require_confirmation)\n",
        "        if self.require_confirmation:\n",
        "            sig = int(self._signal_series.iat[i - 1])\n",
        "            prev_high = self._df['High'].iat[i - 1]\n",
        "            prev_low = self._df['Low'].iat[i - 1]\n",
        "\n",
        "            # подтверждение — пробой high/low предыдущей свечи\n",
        "            confirmed_long = (price > prev_high * (1.0 + self.confirmation_buf))\n",
        "            confirmed_short = (price < prev_low * (1.0 - self.confirmation_buf))\n",
        "\n",
        "            if sig == 1 and not confirmed_long:\n",
        "                return\n",
        "            if sig == -1 and not confirmed_short:\n",
        "                return\n",
        "        else:\n",
        "            sig = int(self._signal_series.iat[i])\n",
        "\n",
        "        if sig == 0:\n",
        "            return\n",
        "\n",
        "        # трендовый фильтр\n",
        "        if self.require_trend:\n",
        "            if np.isnan(self.ema_fast[-1]) or np.isnan(self.ema_slow[-1]):\n",
        "                return\n",
        "            if sig == 1 and not (self.ema_fast[-1] > self.ema_slow[-1]):\n",
        "                return\n",
        "            if sig == -1 and not (self.ema_fast[-1] < self.ema_slow[-1]):\n",
        "                return\n",
        "\n",
        "        # ADX (опционально)\n",
        "        if self.use_adx and (not np.isnan(self.adx[-1])) and (self.adx[-1] < self.adx_threshold):\n",
        "            return\n",
        "\n",
        "        # volume filter\n",
        "        if self.vol_ma is not None and 'Volume' in self._df.columns:\n",
        "            vol = self._df['Volume'].iat[i]\n",
        "            if np.isnan(self.vol_ma[-1]) or vol <= self.vol_ma[-1] * self.vol_mult:\n",
        "                return\n",
        "\n",
        "        # S/R proximity\n",
        "        if self.use_sr_filter:\n",
        "            if sig == 1:\n",
        "                local_min = self.roll_min[-1]\n",
        "                if np.isnan(local_min) or abs(price - local_min) > self.sr_atr_mult * atr:\n",
        "                    return\n",
        "            else:\n",
        "                local_max = self.roll_max[-1]\n",
        "                if np.isnan(local_max) or abs(price - local_max) > self.sr_atr_mult * atr:\n",
        "                    return\n",
        "\n",
        "        # минимальный вес паттерна: возьмём тело свечи, где был паттерн\n",
        "        body_idx = -2 if self.require_confirmation else -1\n",
        "        # надо убедиться, что индекс body_idx существует\n",
        "        if len(self.body) < abs(body_idx):\n",
        "            return\n",
        "        if self.body[body_idx] < self.min_body_atr * atr:\n",
        "            return\n",
        "\n",
        "        # SL/TP (уровни)\n",
        "        if sig == 1:\n",
        "            sl = price - 0.45 * atr\n",
        "            tp = price + 2.5 * atr\n",
        "            stop_distance = price - sl\n",
        "        else:\n",
        "            sl = price + 0.45 * atr\n",
        "            tp = price - 2.5 * atr\n",
        "            stop_distance = sl - price\n",
        "\n",
        "        if stop_distance <= 0 or np.isnan(stop_distance):\n",
        "            return\n",
        "\n",
        "        # размер позиции по риску (fraction of equity)\n",
        "        frac = (self.risk_per_trade * price) / stop_distance\n",
        "        frac = float(np.clip(frac, 0.0, self.max_fraction))\n",
        "\n",
        "        if frac < self.min_fraction:\n",
        "            return\n",
        "\n",
        "        # выставляем ордер\n",
        "        if sig == 1:\n",
        "            self.buy(size=frac, sl=sl, tp=tp)\n",
        "        else:\n",
        "            self.sell(size=frac, sl=sl, tp=tp)\n",
        "\n",
        "\n",
        "\n",
        "bt = Backtest(\n",
        "    df,\n",
        "    PatternIndicatorsStrategy,\n",
        "    cash=1_000_000,\n",
        "    commission=0.0005,      # пример комиссии\n",
        "    trade_on_close=True,    # вход по close свечи, где обнаружен паттерн\n",
        "    exclusive_orders=True   # одна открытая позиция за раз\n",
        ")\n",
        "\n",
        "\n",
        "stats = bt.run()\n",
        "print(stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjnNaX9dzNA8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### V2"
      ],
      "metadata": {
        "id": "xFdLBttopb3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = data_v2.copy()\n",
        "\n",
        "# 1) Переименовываем только OHLC(V) в формат, который требует backtesting.py\n",
        "rename_map = {}\n",
        "if 'open' in df.columns:\n",
        "    rename_map['open'] = 'Open'\n",
        "if 'high' in df.columns:\n",
        "    rename_map['high'] = 'High'\n",
        "if 'low' in df.columns:\n",
        "    rename_map['low'] = 'Low'\n",
        "if 'close' in df.columns:\n",
        "    rename_map['close'] = 'Close'\n",
        "if 'volume' in df.columns:\n",
        "    rename_map['volume'] = 'Volume'\n",
        "\n",
        "df = df.rename(columns=rename_map)"
      ],
      "metadata": {
        "id": "Nk6YBpy-qHsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import talib\n",
        "from backtesting import Backtest, Strategy\n",
        "\n",
        "class PatternStrategyV2(Strategy):\n",
        "    # === параметры стратегии ===\n",
        "    atr_period = 14\n",
        "    ema_fast = 50\n",
        "    ema_slow = 200\n",
        "    confirmation_buf = 0.001\n",
        "    require_confirmation = True\n",
        "    require_trend = True\n",
        "    use_volume_filter = True\n",
        "    vol_mult = 1.15\n",
        "    vol_ma_period = 20\n",
        "    use_adx = False\n",
        "    adx_period = 14\n",
        "    adx_threshold = 20\n",
        "    use_sr_filter = False\n",
        "    sr_lookback = 50\n",
        "    sr_atr_mult = 1.0\n",
        "    min_signal_strength = 0.4     # минимальная сила сигнала из detect_candlestick_patterns_v2\n",
        "    risk_per_trade = 0.005\n",
        "    max_fraction = 0.2\n",
        "    min_fraction = 0.001\n",
        "\n",
        "    def init(self):\n",
        "        df = self.data.df\n",
        "        self.df = df\n",
        "\n",
        "        # Проверим наличие нужных колонок\n",
        "        required_cols = {'Open','High','Low','Close','Signal','Signal_strength','ATR'}\n",
        "        missing = required_cols - set(df.columns)\n",
        "        if missing:\n",
        "            raise ValueError(f\"Отсутствуют колонки: {missing}\")\n",
        "\n",
        "        # Базовые индикаторы\n",
        "        H, L, C, O = df['High'], df['Low'], df['Close'], df['Open']\n",
        "\n",
        "        self.ema_fast_line = self.I(talib.EMA, C, self.ema_fast)\n",
        "        self.ema_slow_line = self.I(talib.EMA, C, self.ema_slow)\n",
        "        self.atr = self.I(lambda h,l,c: talib.ATR(h,l,c, timeperiod=self.atr_period), H,L,C)\n",
        "\n",
        "        if self.use_adx:\n",
        "            self.adx = self.I(lambda h,l,c: talib.ADX(h,l,c,timeperiod=self.adx_period), H,L,C)\n",
        "        else:\n",
        "            self.adx = None\n",
        "\n",
        "        if 'Volume' in df.columns and self.use_volume_filter:\n",
        "            self.vol_ma = self.I(lambda v: pd.Series(v).rolling(self.vol_ma_period).mean().values, df['Volume'])\n",
        "        else:\n",
        "            self.vol_ma = None\n",
        "\n",
        "        if self.use_sr_filter:\n",
        "            self.sr_min = self.I(lambda c: pd.Series(c).rolling(self.sr_lookback).min().values, C)\n",
        "            self.sr_max = self.I(lambda c: pd.Series(c).rolling(self.sr_lookback).max().values, C)\n",
        "        else:\n",
        "            self.sr_min = None\n",
        "            self.sr_max = None\n",
        "\n",
        "    def next(self):\n",
        "        i = len(self.data) - 1\n",
        "        price = self.data.Close[-1]\n",
        "        atr = self.atr[-1]\n",
        "\n",
        "        if np.isnan(price) or np.isnan(atr):\n",
        "            return\n",
        "\n",
        "        # Сигнал и сила\n",
        "        if self.require_confirmation and i < 1:\n",
        "            return\n",
        "        sig = int(self.df['Signal'].iat[i - 1] if self.require_confirmation else self.df['Signal'].iat[i])\n",
        "        sig_strength = float(self.df['Signal_strength'].iat[i - 1] if self.require_confirmation else self.df['Signal_strength'].iat[i])\n",
        "\n",
        "        if sig == 0 or sig_strength < self.min_signal_strength:\n",
        "            return\n",
        "\n",
        "        # подтверждение\n",
        "        if self.require_confirmation:\n",
        "            prev_high = self.df['High'].iat[i - 1]\n",
        "            prev_low = self.df['Low'].iat[i - 1]\n",
        "            confirmed = (\n",
        "                (sig == 1 and price > prev_high * (1.0 + self.confirmation_buf)) or\n",
        "                (sig == -1 and price < prev_low * (1.0 - self.confirmation_buf))\n",
        "            )\n",
        "            if not confirmed:\n",
        "                return\n",
        "\n",
        "        # тренд\n",
        "        if self.require_trend:\n",
        "            if sig == 1 and not (self.ema_fast_line[-1] > self.ema_slow_line[-1]):\n",
        "                return\n",
        "            if sig == -1 and not (self.ema_fast_line[-1] < self.ema_slow_line[-1]):\n",
        "                return\n",
        "\n",
        "        # ADX\n",
        "        if self.use_adx and self.adx is not None:\n",
        "            if np.isnan(self.adx[-1]) or self.adx[-1] < self.adx_threshold:\n",
        "                return\n",
        "\n",
        "        # объём\n",
        "        if self.vol_ma is not None and 'Volume' in self.df.columns:\n",
        "            vol = self.df['Volume'].iat[i]\n",
        "            if np.isnan(self.vol_ma[-1]) or vol <= self.vol_ma[-1] * self.vol_mult:\n",
        "                return\n",
        "\n",
        "        # фильтр S/R\n",
        "        if self.use_sr_filter and self.sr_min is not None and self.sr_max is not None:\n",
        "            if sig == 1:\n",
        "                dist = abs(price - self.sr_min[-1])\n",
        "            else:\n",
        "                dist = abs(price - self.sr_max[-1])\n",
        "            if dist > self.sr_atr_mult * atr:\n",
        "                return\n",
        "\n",
        "        # --- риск-менеджмент ---\n",
        "        if sig == 1:\n",
        "            sl = price - 0.5 * atr\n",
        "            tp = price + 2.5 * atr\n",
        "            stop_dist = price - sl\n",
        "        else:\n",
        "            sl = price + 0.5 * atr\n",
        "            tp = price - 2.5 * atr\n",
        "            stop_dist = sl - price\n",
        "\n",
        "        if stop_dist <= 0:\n",
        "            return\n",
        "\n",
        "        frac = (self.risk_per_trade * price) / stop_dist\n",
        "        frac *= np.clip(sig_strength, 0.3, 1.5)  # сила сигнала увеличивает/уменьшает размер\n",
        "        frac = float(np.clip(frac, self.min_fraction, self.max_fraction))\n",
        "\n",
        "        # --- вход ---\n",
        "        if sig == 1:\n",
        "            self.buy(size=frac, sl=sl, tp=tp)\n",
        "        elif sig == -1:\n",
        "            self.sell(size=frac, sl=sl, tp=tp)\n"
      ],
      "metadata": {
        "id": "8lKV_iV7pdpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bt = Backtest(\n",
        "    df,  # DataFrame после detect_candlestick_patterns_v2\n",
        "    PatternStrategyV2,\n",
        "    cash=1_000_000,\n",
        "    commission=0.0005,\n",
        "    trade_on_close=True,\n",
        "    exclusive_orders=True,\n",
        ")\n",
        "\n",
        "stats = bt.run()\n",
        "# bt.plot()\n",
        "print(stats)\n"
      ],
      "metadata": {
        "id": "QZVMlpqTphi-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}